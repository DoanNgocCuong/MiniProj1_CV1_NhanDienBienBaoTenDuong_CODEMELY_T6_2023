{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiểu model clone và convert GGColab g=và náy cục bộ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tài liệu liên quan: \n",
    "\n",
    "4.1.AIChallenge 2021_PaddleOCR-Vietnamese_hungcao0402\n",
    "\n",
    "- https://github.com/Syun1208/scence-text-paddle-ocr/\n",
    "\n",
    "- (ĐỌC KĨ LINK SAU ĐỂ HIỂU MODEL: http://tutorials.aiclub.cs.uit.edu.vn/index.php/2022/04/20/nhan-dang-chu-tieng-viet-trong-anh-ngoai-canh/#2-bai-toan)\n",
    "\n",
    "(https://aihub.ml/competitions/214#learn_the_details)\n",
    "\n",
    "- Dựa theo SAST_SRN.ipynb setup data, folder và file, convert giữa ggcolab và trên máy cá nhân. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn đã tải lên một số tập tin từ một dự án sử dụng PaddleOCR. Dưới đây là giải thích về công dụng của từng tập tin này:\n",
    "\n",
    "1. `__init__.py`: Trong Python, tập tin `__init__.py` thường được sử dụng để đánh dấu một thư mục là một gói Python. Nó có thể rỗng hoặc chứa mã khởi tạo cho gói.\n",
    "\n",
    "2. `ConvertFromBtcToFormatPaddle.py`: Tên của tập tin này gợi ý rằng nó được sử dụng để chuyển đổi dữ liệu từ một định dạng (có thể là 'Btc') sang định dạng sử dụng được bởi PaddleOCR. Đây có thể là một kịch bản để xử lý và chuẩn bị dữ liệu trước khi áp dụng OCR.\n",
    "\n",
    "3. `crop_image.py`: Tập tin này có thể chứa mã để cắt hình ảnh. Trong OCR, việc cắt hình ảnh có thể giúp tập trung vào những phần chứa văn bản cần nhận dạng, do đó cải thiện độ chính xác.\n",
    "\n",
    "4. `Dockerfile`: Tập tin này được sử dụng để tạo một Docker container. Trong Docker, `Dockerfile` mô tả các bước để thiết lập môi trường, cài đặt các gói phụ thuộc, và cấu hình cần thiết cho ứng dụng hoặc dự án.\n",
    "\n",
    "5. `font-times-new-roman.ttf`: Đây là một tập tin phông chữ (Times New Roman). Trong một số ứng dụng OCR, phông chữ có thể được sử dụng để sinh ra hình ảnh văn bản cho mục đích huấn luyện hoặc thử nghiệm.\n",
    "\n",
    "6. `README.md`: Tập tin này thường chứa thông tin hướng dẫn, mô tả dự án, cách cài đặt và sử dụng dự án. Đây là tập tin thông tin đầu tiên mà người dùng nên đọc khi tìm hiểu về một dự án GitHub.\n",
    "\n",
    "7. `requirements.txt`: Tập tin này chứa danh sách các gói Python cần thiết để cài đặt cho dự án. Nó thường được sử dụng cùng với pip để cài đặt các phụ thuộc.\n",
    "\n",
    "8. `run.sh`: Tập tin này có thể là một script shell để chạy dự án hoặc thực hiện các tác vụ liên quan. Nó thường chứa các dòng lệnh để tự động hóa quá trình khởi động hoặc cấu hình dự án.\n",
    "\n",
    "9. `SAST_SRN.ipynb`: Tập tin Jupyter Notebook này có thể chứa mã, hướng dẫn, và ví dụ về cách sử dụng mô hình OCR như SAST, SRN trong PaddleOCR.\n",
    "\n",
    "10. `setup.py`: Tập tin này thường được sử dụng để cài đặt một gói Python. Nó chứa các thông tin cần thiết để cài đặt và phân phối gói Python, bao gồm các phụ thuộc, thông tin phiên bản, và các thông tin khác.\n",
    "\n",
    "Các tập tin này, kết hợp với nhau, có thể cung cấp một hệ thống hoàn chỉnh cho việc nhận dạng văn bản sử dụng PaddleOCR và có thể được sử dụng cho các mục đích nghiên cứu hoặc ứng dụng thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAST_SRN.ipynb\n",
    "Khi bạn chạy notebook `SAST_SRN.ipynb` trên Google Colab, bạn sẽ thực hiện các bước sau và thu được kết quả tương ứng:\n",
    "\n",
    "1. Huấn Luyện Mô Hình (Training)\n",
    "- **Kết quả**: Bạn sẽ thu được mô hình OCR huấn luyện được trên dữ liệu bạn cung cấp. Mô hình này sẽ bao gồm cả phần phát hiện văn bản (detection) và nhận dạng văn bản (recognition).\n",
    "- **Lưu trữ**: Mô hình huấn luyện sẽ được lưu trữ tại vị trí mà bạn chỉ định trong notebook, thường là trong một thư mục trên Google Drive nếu bạn đã thiết lập kết nối, hoặc trong hệ thống tệp của Google Colab.\n",
    "\n",
    "2. Đánh Giá Mô Hình (Evaluation)\n",
    "- **Kết quả**: Bạn sẽ nhận được các số liệu đánh giá hiệu suất của mô hình, như độ chính xác, F1 score, v.v.\n",
    "- **Lưu trữ**: Kết quả đánh giá có thể được in ra trực tiếp trong notebook hoặc lưu vào tệp log.\n",
    "\n",
    "3. Xuất Mô Hình (Export)\n",
    "- **Kết quả**: Bạn sẽ có mô hình OCR đã được \"đóng gói\" và sẵn sàng cho việc suy luận/inference, thường ở định dạng phù hợp để triển khai trên các ứng dụng khác nhau.\n",
    "- **Lưu trữ**: Mô hình được xuất sẽ lưu trong thư mục chỉ định trong notebook.\n",
    "\n",
    "4. Suy Luận/Inference (Predict text on image)\n",
    "- **Kết quả**: Bạn sẽ thu được kết quả nhận dạng văn bản từ hình ảnh mẫu mà bạn sử dụng để thử nghiệm mô hình.\n",
    "- **Lưu trữ**: Kết quả suy luận có thể được hiển thị trực tiếp trong notebook hoặc lưu vào tệp.\n",
    "\n",
    "### Lưu Ý\n",
    "- Khi làm việc trên Google Colab, lưu ý rằng dữ liệu và mô hình chỉ tồn tại trong thời gian phiên làm việc. Để lưu trữ dài hạn, bạn cần lưu chúng vào Google Drive hoặc tải xuống máy tính cá nhân.\n",
    "- Đảm bảo rằng bạn có đủ không gian lưu trữ và tài nguyên tính toán để chạy các quy trình này, đặc biệt là quá trình huấn luyện mô hình, vì nó có thể yêu cầu nhiều tài nguyên và thời gian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `!python3 ConvertFromBtcToFormatPaddle.py`: \n",
    "Lệnh này chạy tệp Python `ConvertFromBtcToFormatPaddle.py`. Trong môi trường máy tính cá nhân, bạn có thể chạy lệnh tương tự từ terminal hoặc command prompt.\n",
    "\n",
    "Về nội dung của `ConvertFromBtcToFormatPaddle.py`:\n",
    "- Mục đích của mã này là đọc các nhãn từ các tệp trong thư mục `/content/vietnamese/labels/`, xử lý chúng và phân loại vào ba tệp: `train_label.txt`, `test_label.txt`, và `useen_label.txt`.\n",
    "- Mỗi tệp nhãn chứa thông tin về vị trí và nội dung văn bản trong hình ảnh.\n",
    "- Mã này:\n",
    "   - Đọc mỗi tệp nhãn.\n",
    "   - Chia từng dòng thành các phần tử, với các tọa độ và nội dung văn bản được tách rời.\n",
    "   - Định dạng lại thông tin thành định dạng JSON.\n",
    "   - Phân loại hình ảnh vào các tập dữ liệu khác nhau dựa trên tên của chúng. \n",
    "   - Ghi thông tin vào các tệp `train_label.txt`, `test_label.txt`, hoặc `useen_label.txt` tương ứng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File: crop_image.py\n",
    "Xử lý ảnh cho Recognition, hoàn toàn ko phụ thuộc vào việc model Detection đã được train hay chưa. vì là crop ảnh theo các mục detection đã có trong label chứ ko phải là detect theo các chỉ mục sau khi model detect được train. \n",
    "\n",
    "- Mục đích:\n",
    "Xử lý và chuẩn bị dữ liệu hình ảnh và văn bản cho việc huấn luyện một mô hình học máy, có thể là một mô hình nhận dạng văn bản từ hình ảnh (OCR).\n",
    "\n",
    "1. Đầu vào:\n",
    "- Tệp `train_label.txt` chứa danh sách các ảnh và dữ liệu nhãn tương ứng dưới dạng JSON.\n",
    "- Các ảnh từ thư mục `./train/vietnamese/train_images/`.\n",
    "\n",
    "2. Xử lý:\n",
    "- Đọc thông tin từ `train_label.txt`.\n",
    "- Với mỗi ảnh, xác định vùng chứa văn bản và tiến hành cắt ra từ - Lưu trữ các đoạn ảnh cắt ra và nhãn tương ứng như đã mô tả trong hàm `print_draw_crop_rec_res`.\n",
    "\n",
    "3. Đầu ra:\n",
    "- print: \n",
    "đã crop im0027_28.jpg\n",
    "đã crop im0027_29.jpg\n",
    "đã crop im0027_30.jpg\n",
    "đã crop im0027_31.jpg\n",
    "đã crop im0027_32.jpg\n",
    "đã crop im0027_33.jpg\n",
    "đã crop im0027_34.jpg\n",
    "đã crop im0027_35.jpg\n",
    "- Một thư mục chứa các đoạn ảnh cắt ra từ ảnh gốc.   (thư mục img_crop trong thư mục train)\n",
    "- Tệp văn bản `crop_label.txt` chứa thông tin nhãn cho mỗi đoạn ảnh. (trong thư mục train)\n",
    "\n",
    "Đây là một quy trình khá tiêu chuẩn trong xử lý và chuẩn bị dữ liệu cho các tác vụ liên quan đến học máy, nhất là trong lĩnh vực nhận dạng hình ảnh và văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bug: \n",
    "Chỗ nào lỗi đường dẫn tương đối thì thay tuyệt đối\n",
    "```\n",
    "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
    "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "UnicodeEncodeError: 'charmap' codec can't encode character '\\u1ecd' in position 14: character maps to <undefined>\n",
    "```\n",
    "=> Fix: \n",
    "```python\n",
    "with open('./train/crop_label.txt', 'w', encoding='utf-8') as crop_label:\n",
    "    # ... rest of your code ...\n",
    "    crop_label.write(\"{0}\\t{1}\\n\".format(crop_name, text[bno]))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bug: - Run trên gg colab bị lỗi: cần `pip install paddle`, pip thì bị lỗi bánh xe gì đó (lạ vì trên lap Tú đang bị lỗi cái đó mà vẫn cắt được), mình `pip install paddlepaddle-gpu` thì fix được"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong gg colab \n",
    "```\n",
    "%cd /content/gdrive/MyDrive/PaddleOCR\n",
    "!python3 crop_image.py\n",
    "```\n",
    "sửa \n",
    "```\n",
    "with open(r'D:\\Hoc IT\\Doan Ngoc Cuong\\OneDrive - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\ResearchModel\\4.Paddleocr_PaddlePaddle\\4.1.AIChallenge 2021_PaddleOCR-Vietnamese_hungcao0402\\train\\train_label.txt','r', encoding='utf-8') as file_text:\n",
    "```\n",
    "thành\n",
    "```\n",
    "with open(r'/content/gdrive/MyDrive/PaddleOCR/train/train_label.txt','r', encoding='utf-8') as file_text:\n",
    "```\n",
    "\n",
    "Trong máy tính thì mở Folder cha trên vscode, bên trong chứa crop.py và thư mục train rồi run crop.py\n",
    "\n",
    "- Run trên gg colab/trên máy tính crop ảnh nhanh hơn up 50.000 ảnh lên Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "https://github.com/manhph2211/BKAI-Challenge-Vietnamese-OCR/tree/main cuộc thi https://aihub.ml/competitions/214 . \n",
    "\n",
    "Dữ liệu được cung cấp bởi ban tổ chức gồm 3 tập như sau:\n",
    "- Training data: là tập dữ liệu thật có gán nhãn, dùng để huấn luyện mô hình. Tập này gồm 2500 ảnh (trong đó 500 ảnh được cung cấp bởi BKAI và 2000 ảnh được lấy từ tập dữ liệu cung cấp bởi VinAI [1]).\n",
    "- Public test: là tập dữ liệu kiểm thử công khai, dùng trong vòng sơ khảo. Tập dữ liệu này gồm 235 ảnh thật có gán nhãn.\n",
    "- Private test: là tập dữ liệu kiểm thử dùng trong vòng chung kết. Tập này gồm 300 ảnh thật.\n",
    "\n",
    "Down dữ liệu tại đây: https://github.com/manhph2211/BKAI-Challenge-Vietnamese-OCR/tree/main\n",
    "\n",
    "- Xử lý tập VinAI tham khảo tại: http://tutorials.aiclub.cs.uit.edu.vn/index.php/2022/04/20/nhan-dang-chu-tieng-viet-trong-anh-ngoai-canh/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "!git clone https://github.com/hungcao0402/PaddleOCR-Vietnamese\n",
    "\n",
    "!pip install -r /content/PaddleOCR-Vietnamese/requirements.txt\n",
    "\n",
    "!gdown --id 1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml  # download \n",
    "\n",
    "!unzip vietnamese_original.zip -d train        # unzip: giải nén tệp zip, và lưu vào `train` folder\n",
    "\n",
    "!mv /content/train /content/PaddleOCR-Vietnamese   # move 'train' folder to a new location  => lý do sau khi run file ko thấy data được giải nén đâu. \n",
    "```\n",
    "\n",
    "- git clone\n",
    "- cd vào trong và: pip install -r requirements.txt\n",
    "- Down data, giải nén đổi tên thành train, di chuyển thư mục vào trong PaddleOCR-Vietnamese\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Đọc nhãn dán trong thư mục labels, chia vào 3 tập, lưu vào vị trí hiện tại của cmd\n",
    "# ```python \n",
    "# # ConvertFromBtcToFormatPaddle.py\n",
    "\n",
    "# # root_path = glob.glob('/content/vietnamese/labels/*')\n",
    "# root_path = glob.glob('/content/PaddleOCR-Vietnamese/train/vietnamese/labels/*')\n",
    "\n",
    "# train_label = open(\"train_label.txt\",\"w\")   # lưu vào vị trí cmd hiện tại \n",
    "# test_label = open(\"test_label.txt\",\"w\")\n",
    "# useen_label = open(\"useen_label.txt\",\"w\")\n",
    "# ```\n",
    "!python3 ConvertFromBtcToFormatPaddle.py   # run/execute .py  => cần upload nó lên gg colab, VÀ UPLOAD VÀO TRONG PADDLE-OCR VNESE\n",
    "```\n",
    "\n",
    "1. Hoàn thành phần chuẩn bị data và tài nguyên, thư viện trong 4h. \n",
    "=> Train đến 4/300 epoch đi ngủ. Sáng dậy xem sao. => Sáng dậy data bị xóa hết và bị đòi lại GPU Colab. \n",
    "\n",
    "2. Bug: trên gg colab thì `%cd /content/PaddleOCR-Vietnamese` lúc được lúc không. => Mãi mới down được file label thành 3 file. \n",
    "=> fix: `cd /content/gdrive/MyDrive/CHECKPOINTs/PaddleOCR-Vietnamese` khi vào cd rồi thì coi như nó đang ở PaddleOCR-Vietnamese rồi, ko cần `/content` nữa. \n",
    "\n",
    "Còn BUG trên máy: PermissionError: [Errno 13] Permission denied: 'D:\\\\OneDrive - codemely\\\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\\\mycode\\\\ResearchModel\\\\PaddleOCR-Vietnamese\\\\train\\\\vietnamese\\\\labels'\n",
    "\n",
    "=> Run trên gg colab xong down 3 file .txt về bỏ vào thư mục train folder, lát sau lại từ local đẩy lên colab\n",
    "\n",
    "1. **Đọc File**: Sử dụng `glob` để tìm tất cả các file trong thư mục `/content/vietnamese/labels/`. Mỗi file trong thư mục này được xử lý lần lượt.\n",
    "\n",
    "2. **Xử lý Dữ Liệu**: Mỗi file được mở và đọc nội dung của nó. Nội dung của mỗi file chứa thông tin về nhãn (labels) và tọa độ của từng đối tượng trong hình ảnh. Dữ liệu được lưu dưới dạng văn bản, với mỗi dòng tương ứng với một đối tượng.\n",
    "\n",
    "   Ví dụ, dòng `65,35,82,35,82,39,65,39,###` được chuyển thành một đối tượng `label` với:\n",
    "   - `transcription` là `###`\n",
    "   - `points` là một danh sách các điểm `[[\"65\", \"35\"], [\"82\", \"35\"], [\"82\", \"39\"], [\"65\", \"39\"]]`\n",
    "\n",
    "3. **Phân Loại và Lưu Dữ Liệu**: Các nhãn sau khi được xử lý sẽ được chuyển thành định dạng JSON và được phân loại thành ba nhóm: `train`, `test`, và `useen` (có lẽ bạn muốn gọi là `unseen`) dựa trên tên của file ảnh:\n",
    "   - Nếu số trong tên file lớn hơn 1500, nhãn được ghi vào file `useen_label.txt`.\n",
    "   - Nếu số trong tên file lớn hơn 1200 nhưng nhỏ hơn hoặc bằng 1500, nhãn được ghi vào file `test_label.txt`.\n",
    "   - Các trường hợp còn lại, nhãn được ghi vào file `train_label.txt`.\n",
    "\n",
    "4. **Định Dạng Dữ Liệu Lưu Trữ**: Dữ liệu được lưu ở dạng `tên_hình_ảnh\\tchuỗi_JSON\\n` trong mỗi file tương ứng. Chuỗi JSON biểu diễn danh sách các đối tượng `label` với `transcription` và `points` cho mỗi đối tượng trong ảnh.\n",
    "\n",
    "Kết quả là, bạn sẽ có ba file (`train_label.txt`, `test_label.txt`, và `useen_label.txt`) chứa thông tin nhãn dưới dạng JSON cho mỗi hình ảnh, được phân loại dựa trên quy tắc bạn đặt ra (dựa vào số trong tên file ảnh).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Tải xuống 1 file tar từ URL, lưu vào -P \"./pretrain_models\", giải nén nó vào -C\n",
    "!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_r50_vd_sast_icdar15_v2.0_train.tar -P ./pretrain_models \n",
    "!tar -xf ./pretrain_models/det_r50_vd_sast_icdar15_v2.0_train.tar -C /content/PaddleOCR-Vietnamese/pretrain_models\n",
    "\n",
    "# tương tự down model recognition, giải nén và di chuyển vào pretrain_models_srn folder\n",
    "!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_r50_vd_srn_train.tar -P ./pretrain_models_srn\n",
    "!tar -xf ./pretrain_models_srn/rec_r50_vd_srn_train.tar -C /content/PaddleOCR-Vietnamese/pretrain_models_srn\n",
    "\n",
    "```\n",
    "\n",
    "Link down det model: https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_r50_vd_sast_icdar15_v2.0_train.tar\n",
    "Link down rec model: https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_r50_vd_srn_train.tar\n",
    "\n",
    "Trong file config ta có: \n",
    "```\n",
    "  pretrained_model: ./pretrain_models/det_r50_vd_sast_icdar15_v2.0_train/best_accuracy\n",
    "  pretrained_model: ./pretrain_models/SRN/latest     # đường dẫn đến mô hình đã được huấn luyện trước (pretrained model), tự minh down về xong di chuyển vào\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2023/11/11 13:25:53] root ERROR: When parsing line im0178.jpg\t[{\"transcription\": \"An\", \"points\": [[\"292\", \"240\"], [\"386\", \"252\"], [\"407\", \"373\"], [\"277\", \"353\"]]}, {\"transcription\": \"Khang\", \"points\": [[\"220\", \"351\"], [\"469\", \"397\"], [\"457\", \"596\"], [\"183\", \"492\"]]}]\n",
    ", error happened with msg: module 'numpy' has no attribute 'bool'.\n",
    "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
    "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
    "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
    "\n",
    "- Đây giống bug cơ mà chắc ko ảnh hường vì bài gốc cũng bị output như này\n",
    "\n",
    "- Sau fix = 1 file script chạy dọc qua tất cả các file chuyển `np.bool` thành `bool` . Cơ mà sau này set up lại từ nguyên gốc của PaddlePaddle thì ko bị."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sau đó vẫn bug và bị treo ở mãi epoch 1/300 mà mãi ko fix được, sang máy Tú phải set up nhiều thứ lại và bị bug ở cài PaddleOCR `pip install paddleocr` bug\n",
    "\n",
    "- Sau đó clone từ PaddleOCR gốc về, chỉnh sửa để train theo model của scence-text có vẻ khả quan hơn. \n",
    "- Test with epoch = 1, debug_train folder file debug_train_label.txt thu được các file lastest.pad, lastest...., ... 3 file + 1 file train.log + 1 file .yml cấu hình lúc train\n",
    "\n",
    "Đổi ảnh infer_img để null, \n",
    "eval img (ảnh lúc test model từ 1 folder xuống 1 ảnh thui)\n",
    "  character_dict_path: /content/drive/MyDrive/PaddleOCR/ppocr/utils/dict/vi_vietnam.txt    # ký tự tiếng việt\n",
    "  character_type: vi\n",
    "\n",
    "Upload file tiếng việt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để như này   pretrained_model: /content/gdrive/MyDrive/PaddleOCR/pretrain_model_srn/rec_r50_vd_srn_train bị lỗi vì nó sẽ + với .pdparams\n",
    "hoặc như này cũng lỗi /content/gdrive/MyDrive/PaddleOCR/pretrain_model_srn/rec_r50_vd_srn_train/best_accuracy\n",
    "\n",
    "Báo cùng 1 lỗi: `AssertionError: The ./content/gdrive/MyDrive/PaddleOCR/pretrain_model_srn/rec_r50_vd_srn_train.pdparams does not exists!`\n",
    "=> fix: `./pretrain_model_srn/rec_r50_vd_srn_train/best_accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cảnh Báo về Sự Không Tương Thích của Tham Số Mô Hình (Shape Mismatch Warnings):\n",
    "\n",
    "Các cảnh báo như The shape of model params head.gsrm.fc0.weight [512, 222] not matched with loaded params head.gsrm.fc0.weight [512, 38] chỉ ra rằng có sự không khớp về kích thước (shape) giữa các tham số trong mô hình và tham số đã tải. Điều này thường xảy ra khi số lượng ký tự mà mô hình được thiết kế để nhận dạng không phù hợp với số lượng ký tự trong bộ tham số được tải.\n",
    "Ví dụ, [512, 222] so với [512, 38] có nghĩa là mô hình hiện tại được thiết kế để nhận dạng 222 ký tự khác nhau, nhưng bộ tham số được tải chỉ có dữ liệu cho 38 ký tự."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logger trong file program/py (cùng vị trí với file train.py) để logger lại trong quá trình train. \n",
    "- wandbi để theo dõi quá trình train\n",
    "\n",
    "- loader: use share memory Tgpu rue -> cpu: false \n",
    "num_worker đủ để 8, cpu thì để số 0\n",
    "\n",
    "https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/config_en.md\n",
    "\n",
    "wandb: Currently logged in as: doanngoccuong (doanngoccuong_nh). Use `wandb login --relogin` to force relogin\n",
    "```\n",
    "!pip install wandb\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "# c8767797aae76cbcd389ff29929ace1ac3021161\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2023/11/14 17:07:27] ppocr INFO: train_reader_cost: 0.011469841003417969\n",
    "[2023/11/14 17:08:24] ppocr INFO: epoch: [1/3], global_step: 20, lr: 0.010000, acc: 0.000000, norm_edit_dis: 0.000000, loss: 6152.168945, word_loss: 1622.458374, img_loss: 1067.156006, avg_reader_cost: 0.00115 s, avg_batch_cost: 55.80353 s, avg_samples: 32.0, ips: 0.57344 samples/s, eta: 1 day, 13:48:11\n",
    "eval model::   0% 0/807 [00:00<?, ?it/s]Exception in thread Thread-5 (_thread_loop):\n",
    "Traceback (most recent call last):\n",
    "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
    "    self.run()\n",
    "\n",
    "-> ? set eval epoch step = 1 để đánh giá eval\n",
    "\n",
    "\n",
    "\n",
    "Train:\n",
    "  dataset:\n",
    "    name: SimpleDataSet\n",
    "    data_dir: ./train/crop_images\n",
    "train để crop_images và folder cũng để vậy, mà tại sao lỗi cứ báo\n",
    "`Exception: ./train/crop_image/im0444_11.jpg does not exist!\n",
    "eval model::   0% 0/807 [00:07<?, ?it/s]\n",
    "` có thể là liên quan đến cái gì đó ở trong 1 vài file code sẵn => thôi thì đổi tên folder và tên trong config cho thành crop_image vậy, thì chạy được. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval model::   1% 9/807 [03:10<4:32:03, 20.46s/it]  The second part (<4:32:03) is an estimate of how much time is left for the evaluation to complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc = 0? dù là xài model đã được train sẵn là SRN thì sao lại = 0 được? \n",
    "Còn đang train thì gg colab hết Ram nên đơ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
