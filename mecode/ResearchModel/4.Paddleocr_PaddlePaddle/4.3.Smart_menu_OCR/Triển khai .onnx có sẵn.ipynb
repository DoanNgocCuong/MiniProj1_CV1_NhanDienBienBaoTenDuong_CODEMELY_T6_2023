{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triển khai .onnx bằng code (cách mình biên dịch ra from cách anh Tú)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Syun1208/Smart_menu_OCR\n",
    "\n",
    "Use https://netron.app/\n",
    "Model Properties : \n",
    "- producer: PaddlePaddle\n",
    "\n",
    "- Inputs: x name: x; tensor: float32[-1,3,-1,-1]  (mô hình chấp nhận các kích thước batch, độ phân giải hình ảnh khác nhaum nhưng luôn mong 3 kênh màu RGB)\n",
    "Outputs: sigmoid_0.tmp_0 name: sigmoid_0.tmp_0; tensor: float32[-1,1,-1,-1]  (tạo ra giá trị kích hoạt sigmoid cho mỗi đầu vào, có thể có độ phân giải khác nhau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import cv2\n",
    "# from IPython.display import display, Image\n",
    "# from yolov8 import Yolov8\n",
    "\n",
    "# # Set up the Yolo model\n",
    "# model_path = r\"model\\road.onnx\" # r\".\\model\\road.onnx\" # \"path_to_your_model.onnx\" # Replace with the path to your model\n",
    "# yolo_model = PaddlePaddle()\n",
    "# yolo_model.set_up_model(model_path)\n",
    "\n",
    "# # Read the image \n",
    "# frame = cv2.imread(image_path)\n",
    "# results = yolo_model.inference(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort   # thư viện làm việc với onnx\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<onnxruntime.capi.onnxruntime_inference_collection.InferenceSession object at 0x000001B847606190>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the ONNX model\n",
    "model_path = r'models\\model_rec.onnx'  \n",
    "session = ort.InferenceSession(model_path) # print: <onnxruntime.capi.onnxruntime_inference_collection.InferenceSession object at 0x0000022C0F539850>\n",
    "\n",
    "# # Get model's expected input size\n",
    "# input_name = session.get_inputs()[0].name  # print: x\n",
    " # Create an inference session to get the input details\n",
    "# input_details =\n",
    "# session.get_inputs()\n",
    "# output_details = session.get_outputs()\n",
    "# print(*input_details)\n",
    "# print(*output_details)\n",
    "\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeArg(name='x', type='tensor(float)', shape=[None, 3, None, None])\n"
     ]
    }
   ],
   "source": [
    "input_metadata = session.get_inputs()[0]\n",
    "print(input_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[157  82   3]\n",
      "  [150  81   2]\n",
      "  [143  81   5]\n",
      "  ...\n",
      "  [126  75  19]\n",
      "  [146  80  15]\n",
      "  [155  83  11]]\n",
      "\n",
      " [[157  81   5]\n",
      "  [143  75   2]\n",
      "  [130  82  16]\n",
      "  ...\n",
      "  [122  85  35]\n",
      "  [150  89  27]\n",
      "  [155  87  14]]\n",
      "\n",
      " [[159  78  11]\n",
      "  [139  77  17]\n",
      "  [168 146  98]\n",
      "  ...\n",
      "  [132 123  89]\n",
      "  [131  79  26]\n",
      "  [142  80   4]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[157  82   4]\n",
      "  [155  80   1]\n",
      "  [157  82   3]\n",
      "  ...\n",
      "  [118 116  75]\n",
      "  [143  96  35]\n",
      "  [137  70   1]]\n",
      "\n",
      " [[155  79   3]\n",
      "  [155  79   3]\n",
      "  [163  87  11]\n",
      "  ...\n",
      "  [119  79  27]\n",
      "  [146  79  16]\n",
      "  [159  83  11]]\n",
      "\n",
      " [[160  83  10]\n",
      "  [158  81   8]\n",
      "  [159  81  10]\n",
      "  ...\n",
      "  [133  74  18]\n",
      "  [153  77  11]\n",
      "  [166  86  15]]]\n",
      "(12, 31, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "# Read the image \n",
    "image_path = r\"D:\\OneDrive - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\ResearchModel\\4.Paddleocr_PaddlePaddle\\PaddleOCR\\train\\crop_image\\im0001_4.jpg\"\n",
    "img = cv2.imread(image_path)  # (956, 1276, 3) uint8 3\n",
    "print(img)\n",
    "print(img.shape, img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 48, 320) float32\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Đọc hình ảnh\n",
    "# image_path = \"your_image_path.jpg\"\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "img = cv2.resize(img, (320, 48))\n",
    "\n",
    "# Chuyển đổi kiểu dữ liệu sang float và chuẩn hóa (nếu cần)\n",
    "img = img.astype(np.float32) / 255.0\n",
    "\n",
    "# Thay đổi thứ tự kênh từ BGR sang RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Thay đổi hình dạng để thêm chiều batch và đảo kênh màu\n",
    "img = np.transpose(img, (2, 0, 1))  # Chuyển từ HWC sang CHW\n",
    "img = np.expand_dims(img, axis=0)  # Thêm chiều batch\n",
    "\n",
    "print(img.shape, img.dtype)  # Kết quả sẽ là (1, 3, H, W)\n",
    "\n",
    "# NodeArg(name='x', type='tensor(float)', shape=[None, 3, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.01176471, 0.10196079, 0.34901962, ..., 0.1254902 ,\n",
       "          0.05882353, 0.12941177],\n",
       "         [0.01176471, 0.12941177, 0.5254902 , ..., 0.09803922,\n",
       "          0.03137255, 0.2784314 ],\n",
       "         [0.        , 0.12156863, 0.30588236, ..., 0.18039216,\n",
       "          0.03921569, 0.2901961 ],\n",
       "         ...,\n",
       "         [0.        , 0.14117648, 0.3529412 , ..., 0.04313726,\n",
       "          0.03137255, 0.27450982],\n",
       "         [0.00784314, 0.15686275, 0.39607844, ..., 0.05490196,\n",
       "          0.03137255, 0.28235295],\n",
       "         [0.00392157, 0.11372549, 0.30980393, ..., 0.02745098,\n",
       "          0.02745098, 0.24705882]],\n",
       "\n",
       "        [[0.99607843, 0.9254902 , 0.85882354, ..., 0.7411765 ,\n",
       "          0.7647059 , 0.90588236],\n",
       "         [0.99607843, 0.9019608 , 0.85882354, ..., 0.28627452,\n",
       "          0.44313726, 0.8156863 ],\n",
       "         [1.        , 0.9098039 , 0.65882355, ..., 0.3254902 ,\n",
       "          0.42352942, 0.79607844],\n",
       "         ...,\n",
       "         [1.        , 0.8980392 , 0.6117647 , ..., 0.2509804 ,\n",
       "          0.36862746, 0.8       ],\n",
       "         [1.        , 0.9019608 , 0.6431373 , ..., 0.22745098,\n",
       "          0.3529412 , 0.8039216 ],\n",
       "         [0.99607843, 0.90588236, 0.6745098 , ..., 0.30588236,\n",
       "          0.42352942, 0.8235294 ]],\n",
       "\n",
       "        [[0.01568628, 0.0627451 , 0.23137255, ..., 0.12156863,\n",
       "          0.0627451 , 0.13333334],\n",
       "         [0.01176471, 0.12941177, 0.5176471 , ..., 0.08627451,\n",
       "          0.03137255, 0.27058825],\n",
       "         [0.        , 0.11764706, 0.2901961 , ..., 0.16078432,\n",
       "          0.03137255, 0.2901961 ],\n",
       "         ...,\n",
       "         [0.        , 0.11764706, 0.27450982, ..., 0.15686275,\n",
       "          0.03529412, 0.31764707],\n",
       "         [0.01568628, 0.13333334, 0.3019608 , ..., 0.1254902 ,\n",
       "          0.03529412, 0.30980393],\n",
       "         [0.00784314, 0.08235294, 0.20784314, ..., 0.02352941,\n",
       "          0.02745098, 0.23921569]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bug: `RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Add node. Name:'Add_43' Status Message: C:\\a\\_work\\1\\s\\onnxruntime\\core/providers/cpu/math/element_wise_ops.h:540 onnxruntime::BroadcastIterator::Init axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 171 by 172`\n",
    "```\n",
    "img = cv2.resize(img, (320, 48))     # width, height\n",
    "# output: (1, 3, 48, 320) float32    # height, width\n",
    "```\n",
    "(xem code .pynb file config mới xem được input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Đường dẫn đến mô hình ONNX\n",
    "model_path = r'models\\model_rec.onnx'  \n",
    "# Tạo phiên làm việc\n",
    "session = ort.InferenceSession(model_path)\n",
    "\n",
    "# Hình ảnh đã được chuẩn bị trước đó\n",
    "# img là mảng Numpy có hình dạng (1, 3, H, W) và kiểu dữ liệu float32\n",
    "# Giả sử img là biến chứa hình ảnh của bạn\n",
    "\n",
    "# Tên của đầu vào mô hình\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "# Chạy mô hình\n",
    "result = session.run(None, {input_name: img})\n",
    "\n",
    "# `result` là kết quả đầu ra từ mô hình\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[9.9999356e-01, 4.6411208e-10, 4.6411208e-10, ...,\n",
      "         2.6939439e-11, 3.0204095e-10, 6.8069611e-10],\n",
      "        [9.9999952e-01, 4.2150974e-11, 4.2150974e-11, ...,\n",
      "         8.7819926e-13, 5.9837010e-11, 1.5811470e-11],\n",
      "        [9.9947959e-01, 1.8059455e-10, 1.8059455e-10, ...,\n",
      "         3.2141661e-12, 4.3247047e-12, 8.7900513e-11],\n",
      "        ...,\n",
      "        [9.9979633e-01, 3.0662239e-09, 3.0662239e-09, ...,\n",
      "         2.6023136e-10, 3.8308956e-14, 2.2714611e-08],\n",
      "        [9.9992764e-01, 1.3794557e-09, 1.3794557e-09, ...,\n",
      "         5.9319011e-10, 3.9860102e-13, 3.1962479e-08],\n",
      "        [9.9950695e-01, 8.9806838e-09, 8.9806838e-09, ...,\n",
      "         6.0985803e-09, 1.0842493e-11, 1.7297900e-06]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[9.9999058e-01, 2.2108303e-10, 2.2108303e-10, ...,\n",
       "          4.4091963e-11, 7.2908644e-11, 1.7470663e-07],\n",
       "         [9.9942732e-01, 9.0514429e-11, 9.0514429e-11, ...,\n",
       "          1.8815192e-11, 5.8281743e-12, 1.2725997e-07],\n",
       "         [9.9716312e-01, 5.6898691e-10, 5.6898691e-10, ...,\n",
       "          5.8910565e-10, 5.2930084e-11, 2.4724295e-07],\n",
       "         ...,\n",
       "         [6.2271833e-01, 1.6556901e-07, 1.6556901e-07, ...,\n",
       "          8.5196945e-07, 4.4482681e-06, 2.2573523e-04],\n",
       "         [9.9261910e-01, 2.1259661e-08, 2.1259661e-08, ...,\n",
       "          8.2278952e-08, 6.4409875e-08, 3.6616533e-04],\n",
       "         [9.9852353e-01, 1.6765169e-08, 1.6765169e-08, ...,\n",
       "          3.4315533e-09, 4.5951390e-10, 2.1179987e-04]]], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: predict_system.py [-h] [--use_gpu USE_GPU] [--use_xpu USE_XPU]\n",
      "                         [--ir_optim IR_OPTIM] [--use_tensorrt USE_TENSORRT]\n",
      "                         [--min_subgraph_size MIN_SUBGRAPH_SIZE]\n",
      "                         [--precision PRECISION] [--gpu_mem GPU_MEM]\n",
      "                         [--image_dir IMAGE_DIR]\n",
      "                         [--det_algorithm DET_ALGORITHM]\n",
      "                         [--det_model_dir DET_MODEL_DIR]\n",
      "                         [--det_limit_side_len DET_LIMIT_SIDE_LEN]\n",
      "                         [--det_limit_type DET_LIMIT_TYPE]\n",
      "                         [--det_db_thresh DET_DB_THRESH]\n",
      "                         [--det_db_box_thresh DET_DB_BOX_THRESH]\n",
      "                         [--det_db_unclip_ratio DET_DB_UNCLIP_RATIO]\n",
      "                         [--max_batch_size MAX_BATCH_SIZE]\n",
      "                         [--use_dilation USE_DILATION]\n",
      "                         [--det_db_score_mode DET_DB_SCORE_MODE]\n",
      "                         [--vis_seg_map VIS_SEG_MAP]\n",
      "                         [--det_east_score_thresh DET_EAST_SCORE_THRESH]\n",
      "                         [--det_east_cover_thresh DET_EAST_COVER_THRESH]\n",
      "                         [--det_east_nms_thresh DET_EAST_NMS_THRESH]\n",
      "                         [--det_sast_score_thresh DET_SAST_SCORE_THRESH]\n",
      "                         [--det_sast_nms_thresh DET_SAST_NMS_THRESH]\n",
      "                         [--det_sast_polygon DET_SAST_POLYGON]\n",
      "                         [--det_pse_thresh DET_PSE_THRESH]\n",
      "                         [--det_pse_box_thresh DET_PSE_BOX_THRESH]\n",
      "                         [--det_pse_min_area DET_PSE_MIN_AREA]\n",
      "                         [--det_pse_box_type DET_PSE_BOX_TYPE]\n",
      "                         [--det_pse_scale DET_PSE_SCALE] [--scales SCALES]\n",
      "                         [--alpha ALPHA] [--beta BETA]\n",
      "                         [--fourier_degree FOURIER_DEGREE]\n",
      "                         [--det_fce_box_type DET_FCE_BOX_TYPE]\n",
      "                         [--rec_algorithm REC_ALGORITHM]\n",
      "                         [--rec_model_dir REC_MODEL_DIR]\n",
      "                         [--rec_image_shape REC_IMAGE_SHAPE]\n",
      "                         [--rec_batch_num REC_BATCH_NUM]\n",
      "                         [--max_text_length MAX_TEXT_LENGTH]\n",
      "                         [--rec_char_dict_path REC_CHAR_DICT_PATH]\n",
      "                         [--use_space_char USE_SPACE_CHAR]\n",
      "                         [--vis_font_path VIS_FONT_PATH]\n",
      "                         [--drop_score DROP_SCORE]\n",
      "                         [--e2e_algorithm E2E_ALGORITHM]\n",
      "                         [--e2e_model_dir E2E_MODEL_DIR]\n",
      "                         [--e2e_limit_side_len E2E_LIMIT_SIDE_LEN]\n",
      "                         [--e2e_limit_type E2E_LIMIT_TYPE]\n",
      "                         [--e2e_pgnet_score_thresh E2E_PGNET_SCORE_THRESH]\n",
      "                         [--e2e_char_dict_path E2E_CHAR_DICT_PATH]\n",
      "                         [--e2e_pgnet_valid_set E2E_PGNET_VALID_SET]\n",
      "                         [--e2e_pgnet_mode E2E_PGNET_MODE]\n",
      "                         [--use_angle_cls USE_ANGLE_CLS]\n",
      "                         [--cls_model_dir CLS_MODEL_DIR]\n",
      "                         [--cls_image_shape CLS_IMAGE_SHAPE]\n",
      "                         [--label_list LABEL_LIST]\n",
      "                         [--cls_batch_num CLS_BATCH_NUM]\n",
      "                         [--cls_thresh CLS_THRESH]\n",
      "                         [--enable_mkldnn ENABLE_MKLDNN]\n",
      "                         [--cpu_threads CPU_THREADS]\n",
      "                         [--use_pdserving USE_PDSERVING] [--warmup WARMUP]\n",
      "                         [--draw_img_save_dir DRAW_IMG_SAVE_DIR]\n",
      "                         [--save_crop_res SAVE_CROP_RES]\n",
      "                         [--crop_res_save_dir CROP_RES_SAVE_DIR]\n",
      "                         [--use_mp USE_MP]\n",
      "                         [--total_process_num TOTAL_PROCESS_NUM]\n",
      "                         [--process_id PROCESS_ID] [--benchmark BENCHMARK]\n",
      "                         [--save_log_path SAVE_LOG_PATH] [--show_log SHOW_LOG]\n",
      "                         [--use_onnx USE_ONNX]\n",
      "predict_system.py: error: unrecognized arguments: - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\ResearchModel\\4.Paddleocr_PaddlePaddle\\PaddleOCR\\train\\debug_train_images'\n",
      "usage: predict_system.py [-h] [--use_gpu USE_GPU] [--use_xpu USE_XPU]\n",
      "                         [--ir_optim IR_OPTIM] [--use_tensorrt USE_TENSORRT]\n",
      "                         [--min_subgraph_size MIN_SUBGRAPH_SIZE]\n",
      "                         [--precision PRECISION] [--gpu_mem GPU_MEM]\n",
      "                         [--image_dir IMAGE_DIR]\n",
      "                         [--det_algorithm DET_ALGORITHM]\n",
      "                         [--det_model_dir DET_MODEL_DIR]\n",
      "                         [--det_limit_side_len DET_LIMIT_SIDE_LEN]\n",
      "                         [--det_limit_type DET_LIMIT_TYPE]\n",
      "                         [--det_db_thresh DET_DB_THRESH]\n",
      "                         [--det_db_box_thresh DET_DB_BOX_THRESH]\n",
      "                         [--det_db_unclip_ratio DET_DB_UNCLIP_RATIO]\n",
      "                         [--max_batch_size MAX_BATCH_SIZE]\n",
      "                         [--use_dilation USE_DILATION]\n",
      "                         [--det_db_score_mode DET_DB_SCORE_MODE]\n",
      "                         [--vis_seg_map VIS_SEG_MAP]\n",
      "                         [--det_east_score_thresh DET_EAST_SCORE_THRESH]\n",
      "                         [--det_east_cover_thresh DET_EAST_COVER_THRESH]\n",
      "                         [--det_east_nms_thresh DET_EAST_NMS_THRESH]\n",
      "                         [--det_sast_score_thresh DET_SAST_SCORE_THRESH]\n",
      "                         [--det_sast_nms_thresh DET_SAST_NMS_THRESH]\n",
      "                         [--det_sast_polygon DET_SAST_POLYGON]\n",
      "                         [--det_pse_thresh DET_PSE_THRESH]\n",
      "                         [--det_pse_box_thresh DET_PSE_BOX_THRESH]\n",
      "                         [--det_pse_min_area DET_PSE_MIN_AREA]\n",
      "                         [--det_pse_box_type DET_PSE_BOX_TYPE]\n",
      "                         [--det_pse_scale DET_PSE_SCALE] [--scales SCALES]\n",
      "                         [--alpha ALPHA] [--beta BETA]\n",
      "                         [--fourier_degree FOURIER_DEGREE]\n",
      "                         [--det_fce_box_type DET_FCE_BOX_TYPE]\n",
      "                         [--rec_algorithm REC_ALGORITHM]\n",
      "                         [--rec_model_dir REC_MODEL_DIR]\n",
      "                         [--rec_image_shape REC_IMAGE_SHAPE]\n",
      "                         [--rec_batch_num REC_BATCH_NUM]\n",
      "                         [--max_text_length MAX_TEXT_LENGTH]\n",
      "                         [--rec_char_dict_path REC_CHAR_DICT_PATH]\n",
      "                         [--use_space_char USE_SPACE_CHAR]\n",
      "                         [--vis_font_path VIS_FONT_PATH]\n",
      "                         [--drop_score DROP_SCORE]\n",
      "                         [--e2e_algorithm E2E_ALGORITHM]\n",
      "                         [--e2e_model_dir E2E_MODEL_DIR]\n",
      "                         [--e2e_limit_side_len E2E_LIMIT_SIDE_LEN]\n",
      "                         [--e2e_limit_type E2E_LIMIT_TYPE]\n",
      "                         [--e2e_pgnet_score_thresh E2E_PGNET_SCORE_THRESH]\n",
      "                         [--e2e_char_dict_path E2E_CHAR_DICT_PATH]\n",
      "                         [--e2e_pgnet_valid_set E2E_PGNET_VALID_SET]\n",
      "                         [--e2e_pgnet_mode E2E_PGNET_MODE]\n",
      "                         [--use_angle_cls USE_ANGLE_CLS]\n",
      "                         [--cls_model_dir CLS_MODEL_DIR]\n",
      "                         [--cls_image_shape CLS_IMAGE_SHAPE]\n",
      "                         [--label_list LABEL_LIST]\n",
      "                         [--cls_batch_num CLS_BATCH_NUM]\n",
      "                         [--cls_thresh CLS_THRESH]\n",
      "                         [--enable_mkldnn ENABLE_MKLDNN]\n",
      "                         [--cpu_threads CPU_THREADS]\n",
      "                         [--use_pdserving USE_PDSERVING] [--warmup WARMUP]\n",
      "                         [--draw_img_save_dir DRAW_IMG_SAVE_DIR]\n",
      "                         [--save_crop_res SAVE_CROP_RES]\n",
      "                         [--crop_res_save_dir CROP_RES_SAVE_DIR]\n",
      "                         [--use_mp USE_MP]\n",
      "                         [--total_process_num TOTAL_PROCESS_NUM]\n",
      "                         [--process_id PROCESS_ID] [--benchmark BENCHMARK]\n",
      "                         [--save_log_path SAVE_LOG_PATH] [--show_log SHOW_LOG]\n",
      "                         [--use_onnx USE_ONNX]\n",
      "predict_system.py: error: unrecognized arguments: - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\ResearchModel\\4.Paddleocr_PaddlePaddle\\PaddleOCR\\train\\debug_train_images'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python tools/infer/predict_system.py --use_gpu=True --use_onnx=True --drop_score=0.7\\\n",
    "--det_algorithm=\"DB\" --use_mp=True --total_process_num=2 \\\n",
    "--image_dir=r'D:\\OneDrive - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\ResearchModel\\4.Paddleocr_PaddlePaddle\\PaddleOCR\\train\\debug_train_images' \\\n",
    "--det_model_dir=/content/drive/MyDrive/PPOCR/output/onnx_model/det_ppocrv3_onnx/model_det.onnx  \\\n",
    "--rec_model_dir=/content/drive/MyDrive/PPOCR/output/onnx_model/rec_ppocrv3_onnx/model_rec.onnx \\\n",
    "--rec_char_dict_path=\"/configs/dictionary/ppocr_dict.txt\" \\\n",
    "--draw_img_save_dir='/ONNX' \\\n",
    "--vis_font_path='models\\latin.ttf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float32' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Hoc IT\\Doan Ngoc Cuong\\OneDrive - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\ResearchModel\\4.Paddleocr_PaddlePaddle\\4.3.Smart_menu_OCR\\Triển khai .onnx có sẵn.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Giả sử output là tensor đầu ra từ mô hình của bạn\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[[\u001b[39m9.9999058e-01\u001b[39m, \u001b[39m2.2108303e-10\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]], dtype\u001b[39m=\u001b[39mfloat32)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Chọn kênh đầu tiên (hoặc bất kỳ kênh nào bạn muốn biểu diễn)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m heatmap \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, :]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'float32' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Giả sử output là tensor đầu ra từ mô hình của bạn\n",
    "output = np.array([[[9.9999058e-01, 2.2108303e-10, ...]]], dtype=float32)\n",
    "\n",
    "# Chọn kênh đầu tiên (hoặc bất kỳ kênh nào bạn muốn biểu diễn)\n",
    "heatmap = output[0, 0, :]\n",
    "\n",
    "# Tạo heatmap\n",
    "plt.imshow(heatmap, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Hoc IT\\Doan Ngoc Cuong\\OneDrive - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\ResearchModel\\4.Paddleocr_PaddlePaddle\\4.3.Smart_menu_OCR\\Triển khai .onnx có sẵn.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Giả sử `array_data` là mảng của bạn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# array_data = np.array([[...]])  # Thay thế bằng mảng thực tế của bạn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Chọn kênh hoặc xử lý mảng ở đây nếu cần\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Chuẩn hóa dữ liệu (ví dụ này giả sử dữ liệu đã nằm trong khoảng 0-1)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m image_data \u001b[39m=\u001b[39m (result \u001b[39m*\u001b[39;49m \u001b[39m255\u001b[39;49m)\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Chuyển đổi thành hình ảnh\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Hoc%20IT/Doan%20Ngoc%20Cuong/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/ResearchModel/4.Paddleocr_PaddlePaddle/4.3.Smart_menu_OCR/Tri%E1%BB%83n%20khai%20.onnx%20c%C3%B3%20s%E1%BA%B5n.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(image_data)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Giả sử `array_data` là mảng của bạn\n",
    "# array_data = np.array([[...]])  # Thay thế bằng mảng thực tế của bạn\n",
    "\n",
    "# Chọn kênh hoặc xử lý mảng ở đây nếu cần\n",
    "\n",
    "# Chuẩn hóa dữ liệu (ví dụ này giả sử dữ liệu đã nằm trong khoảng 0-1)\n",
    "image_data = (result * 255).astype(np.uint8)\n",
    "\n",
    "# Chuyển đổi thành hình ảnh\n",
    "image = Image.fromarray(image_data)\n",
    "\n",
    "# Hiển thị hoặc lưu hình ảnh\n",
    "image.show()  # Hoặc image.save(\"output.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Resize img chỉ thực hiện trên 2D, 3D nên cần làm trước khi thao tác khác\n",
    "# side_length = min(img.shape[0], img.shape[1])\n",
    "# # print(side_length)\n",
    "# img = cv2.resize(img, (side_length, side_length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimensions :  (1, 3, 1364, 1364)\n",
      "Image Data Type  :  float32\n",
      "Number of Channels:  1364\n",
      "(1, 3, 1364, 1364) float32 1364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# #1. Convert the image to float32, (if ko có: Unexpected input, actual: (tensor(unit(8)), expected tensor(float))\n",
    "# img = img.astype('float32')     # (956, 1276, 3) float32 3\n",
    "\n",
    "# #2. Add an extra dimension   (Nếu ko có thì: INVALID_ARGUMENT: invalid rank for input x. Got 3 expected 4)\n",
    "# img = np.expand_dims(img, axis=0)    # (1, 956, 1276, 3) float32 1276\n",
    "# # Add an Extra Dimension: You added an extra dimension to the image to make it a batch of images.\n",
    "# #  The shape becomes (1, 956, 1276, 3), which is (batch_size, height, width, channels).\n",
    "\n",
    "# # 3. INVALID_ARGUMENT : Got invalid dimensions for input: x for the following indices index: 1 Got: 956 Expected: 3\n",
    "# # Most likely, your model expects the input in a different order,\n",
    "# #  probably (batch_size, channels, height, width).\n",
    "# # img = np.transpose(img, (2, 0, 1)) # Use numpy.transpose to reorder the dimensions.\n",
    "# img = np.transpose(img, (0, 3, 1, 2))  # Rearrange to (batch_size, channels, height, width) # (1, 3, 956, 1276) float32 956\n",
    "\n",
    "# # Print image information\n",
    "# if img is not None:\n",
    "#     print(\"Image Dimensions : \", img.shape)  # Height, Width, Channels\n",
    "#     print(\"Image Data Type  : \", img.dtype)\n",
    "#     print(\"Number of Channels: \", img.shape[2] if len(img.shape) > 2 else 1)\n",
    "#     print(img.shape, img.dtype, img.shape[2] if len(img.shape) > 2 else 1)\n",
    "# else:\n",
    "#     print(\"Error: Image not loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeException",
     "evalue": "[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Add node. Name:'Add_43' Status Message: C:\\a\\_work\\1\\s\\onnxruntime\\core/providers/cpu/math/element_wise_ops.h:540 onnxruntime::BroadcastIterator::Init axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 171 by 172\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\PaddleOCR-Vietnamese-Pretrained.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/PaddleOCR-Vietnamese-Pretrained.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/PaddleOCR-Vietnamese-Pretrained.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m outputs \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrun(\u001b[39mNone\u001b[39;49;00m, {input_name: img})\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20codemely/Proj1_NhanDienBienBaoTenDuong_CODEMELY/mycode/PaddleOCR-Vietnamese-Pretrained.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m] \u001b[39m# The output is typically a tensor of shape [-1, 1, -1, -1]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    218\u001b[0m     output_names \u001b[39m=\u001b[39m [output\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_meta]\n\u001b[0;32m    219\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(output_names, input_feed, run_options)\n\u001b[0;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m C\u001b[39m.\u001b[39mEPFail \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mRuntimeException\u001b[0m: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Add node. Name:'Add_43' Status Message: C:\\a\\_work\\1\\s\\onnxruntime\\core/providers/cpu/math/element_wise_ops.h:540 onnxruntime::BroadcastIterator::Init axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 171 by 172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Run the model\n",
    "# outputs = session.run(None, {input_name: img})\n",
    "# output = outputs[0] # The output is typically a tensor of shape [-1, 1, -1, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeException                          Traceback (most recent call last)\n",
    "d:\\OneDrive - codemely\\Proj1_NhanDienBienBaoTenDuong_CODEMELY\\mycode\\PaddleOCR-Vietnamese-Pretrained.ipynb Cell 8 line 2\n",
    "      1 # Run the model\n",
    "----> 2 outputs = session.run(None, {input_name: img})\n",
    "      3 output = outputs[0] # The output is typically a tensor of shape [-1, 1, -1, -1]\n",
    "\n",
    "File c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:220, in Session.run(self, output_names, input_feed, run_options)\n",
    "    218     output_names = [output.name for output in self._outputs_meta]\n",
    "    219 try:\n",
    "--> 220     return self._sess.run(output_names, input_feed, run_options)\n",
    "    221 except C.EPFail as err:\n",
    "    222     if self._enable_fallback:\n",
    "\n",
    "RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Add node. Name:'Add_44' Status Message: C:\\a\\_work\\1\\s\\onnxruntime\\core/providers/cpu/math/element_wise_ops.h:540 onnxruntime::BroadcastIterator::Init axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 319 by 320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lỗi mà bạn gặp phải khi chạy model ONNX là do sự không tương thích giữa đầu vào của model và dữ liệu bạn cung cấp. Lỗi `RuntimeException` với thông báo:\n",
    "\n",
    "```\n",
    "Non-zero status code returned while running Add node. Name:'Add_44' Status Message: C:\\a\\_work\\1\\s\\onnxruntime\\core/providers/cpu/math/element_wise_ops.h:540 onnxruntime::BroadcastIterator::Init axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 319 by 320\n",
    "```\n",
    "\n",
    "cho thấy có vấn đề với quá trình broadcast (phát sóng) trong một phép toán cộng. Điều này thường xảy ra khi kích thước của tensor đầu vào không phù hợp với những gì model mong đợi. Để khắc phục lỗi này, bạn cần đảm bảo rằng tensor đầu vào của bạn phải có kích thước phù hợp với model.\n",
    "\n",
    "Dựa trên thông tin bạn cung cấp, có vẻ như model của bạn mong đợi dữ liệu đầu vào có kích thước cụ thể. Bạn đã thực hiện một số thao tác như chuyển đổi kiểu dữ liệu, thêm một chiều (batch size), và sắp xếp lại các kênh màu. Tuy nhiên, có thể model của bạn cần thêm bước xử lý hoặc cần dữ liệu đầu vào với kích thước cụ thể.\n",
    "\n",
    "Để chẩn đoán và sửa lỗi này, bạn có thể thử các bước sau:\n",
    "\n",
    "1. **Kiểm Tra Kích Thước Đầu Vào Mong Đợi của Model**: Sử dụng `session.get_inputs()[0].shape` để xác định kích thước chính xác mà model mong đợi. Điều này sẽ giúp bạn hiểu cần phải điều chỉnh kích thước của ảnh như thế nào.\n",
    "\n",
    "2. **Điều Chỉnh Kích Thước Ảnh**: Nếu kích thước ảnh không phù hợp, sử dụng OpenCV hoặc Numpy để thay đổi kích thước ảnh trước khi đưa vào model. \n",
    "\n",
    "3. **Kiểm Tra Preprocessing**: Đảm bảo rằng các bước tiền xử lý (như chuẩn hóa, trừ mean, v.v.) phù hợp với yêu cầu của model.\n",
    "\n",
    "Nếu bạn có thể cung cấp thêm thông tin về đầu vào mong đợi của model (như kích thước tensor đầu vào), tôi có thể giúp bạn chi tiết hơn trong việc điều chỉnh code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cảm ơn bạn đã cung cấp thông tin chi tiết về model ONNX. Dựa vào thông tin này, model của bạn mong đợi đầu vào là tensor với kích thước [-1, 3, -1, -1], nghĩa là:\n",
    "\n",
    "- Chiều đầu tiên (-1) là kích thước batch, có thể thay đổi.\n",
    "- Chiều thứ hai (3) là số kênh màu, ở đây là 3, tương ứng với màu RGB.\n",
    "- Hai chiều cuối cùng (-1, -1) là chiều cao và rộng của hình ảnh, có thể thay đổi.\n",
    "\n",
    "Do đó, có vẻ như bạn đã xử lý đúng các bước cần thiết để chuẩn bị dữ liệu đầu vào cho model. Bạn đã chuyển đổi kiểu dữ liệu của ảnh thành float32, thêm một chiều cho batch size, và sắp xếp lại các kênh màu để có tensor có hình dạng (1, 3, chiều cao, chiều rộng).\n",
    "\n",
    "Tuy nhiên, lỗi bạn gặp phải có thể xuất phát từ việc kích thước của ảnh không tương thích với mô hình. Lỗi \"broadcast\" xảy ra khi kích thước của tensor không phù hợp để thực hiện phép toán (ví dụ: phép cộng) giữa các tensor.\n",
    "\n",
    "Để giải quyết lỗi này, bạn có thể thử các bước sau:\n",
    "\n",
    "1. **Kiểm Tra Kích Thước của Ảnh**: Đảm bảo rằng kích thước của ảnh (chiều cao và chiều rộng) phù hợp với những gì mà model có thể xử lý. Nếu cần, hãy thay đổi kích thước của ảnh để phù hợp hơn.\n",
    "\n",
    "2. **Điều Chỉnh Preprocessing Đầu Vào**: Nếu model yêu cầu bất kỳ bước chuẩn bị đặc biệt nào cho dữ liệu đầu vào (như chuẩn hóa, trừ mean, v.v.), hãy đảm bảo rằng bạn thực hiện những bước này trước khi đưa ảnh vào model.\n",
    "\n",
    "3. **Xem Xét Đầu Ra của Model**: Đảm bảo bạn hiểu và xử lý đúng đầu ra của model. Trong trường hợp này, model trả về giá trị kích hoạt sigmoid, bạn cần xử lý kết quả này phù hợp với nhu cầu của bạn.\n",
    "\n",
    "Nếu bạn thử những bước trên và vẫn gặp lỗi, hãy cung cấp thêm thông tin về cách bạn xử lý ảnh và đầu ra của model, tôi có thể giúp bạn chi tiết hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tôi thấy node Add_44 rồi, \n",
    "Name:'Add_44' Status Message: C:\\a\\_work\\1\\s\\onnxruntime\\core/providers/cpu/math/element_wise_ops.h:540 onnxruntime::BroadcastIterator::Init axis == 1 || axis == largest was false. Attempting to broadcast an axis by a dimension other than 1. 319 by 320\n",
    "\n",
    "là sao? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thông điệp lỗi mà bạn đã nhận được khi chạy mô hình ONNX của bạn trên ONNX Runtime cung cấp thông tin quan trọng về vấn đề bạn đang gặp phải. Hãy phân tích thông điệp lỗi này:\n",
    "\n",
    "1. **Node Gây Lỗi**: Node gây ra lỗi được định danh là `Add_44`, cho thấy rằng lỗi xảy ra trong một hoạt động cộng.\n",
    "\n",
    "2. **Thông Điệp Lỗi**: Phần thông điệp lỗi \"Attempting to broadcast an axis by a dimension other than 1. 319 by 320\" chỉ ra rằng một trong các tensor đầu vào của hoạt động cộng này đang cố gắng thực hiện broadcasting trên một trục có kích thước khác với 1. Trong trường hợp này, có vẻ như mô hình đang cố gắng broadcast một tensor có kích thước 319 trên một trục mà tensor kia có kích thước là 320.\n",
    "\n",
    "3. **Ý Nghĩa của Lỗi**: Broadcasting trong ONNX và các thư viện tính toán tensor như NumPy cho phép mở rộng tự động các tensor nhỏ hơn để phù hợp với kích thước của tensor lớn hơn trong các phép toán như cộng, nhân, v.v. Tuy nhiên, điều này chỉ hoạt động khi kích thước của tensor nhỏ hơn là 1 ở các trục cần broadcast. Trong trường hợp này, lỗi xảy ra vì một trục có kích thước 319 không thể tự động được mở rộng để phù hợp với kích thước 320.\n",
    "\n",
    "4. **Giải Quyết Lỗi**: Để giải quyết vấn đề này, bạn cần đảm bảo rằng các tensor đầu vào của node `Add_44` có kích thước tương thích với nhau. Nếu mục đích là sử dụng broadcasting, thì kích thước của tensor nhỏ hơn ở trục cần broadcast phải là 1, hoặc bạn cần thực hiện các bước tiền xử lý để đưa chúng về kích thước tương thích trước khi thực hiện phép cộng.\n",
    "\n",
    "Bạn có thể kiểm tra chi tiết các tensor đầu vào của node `Add_44` trong mô hình ONNX của bạn để xác định cách tốt nhất để giải quyết vấn đề này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi nói đến \"broadcasting\" trong ngữ cảnh của mạng neuron và xử lý tensor, chúng ta đang nói về một cơ chế tự động mở rộng dữ liệu của tensor nhỏ hơn để phù hợp với kích thước của tensor lớn hơn trong quá trình thực hiện các phép toán như cộng hoặc nhân. Một \"trục\" trong tensor là một chiều của nó, như chiều rộng, chiều cao, hoặc số kênh trong ảnh.\n",
    "\n",
    "Đối với broadcasting, điều quan trọng là:\n",
    "\n",
    "- **Kích Thước Tensor Nhỏ Hơn Ở Trục Cần Broadcast Là 1**: Nghĩa là trong tensor nhỏ hơn, kích thước của trục cụ thể đó phải là 1. Điều này cho phép tensor đó được \"mở rộng\" tự động để phù hợp với kích thước của tensor lớn hơn trên trục đó.\n",
    "\n",
    "Ví dụ:\n",
    "\n",
    "- Giả sử bạn có hai tensor A và B. A có kích thước [1, 3, 4, 4] và B có kích thước [2, 3, 4, 4].\n",
    "- Ở đây, tensor A có thể được broadcast trên trục đầu tiên từ kích thước 1 lên 2 để phù hợp với kích thước của B.\n",
    "- Kết quả là, A sẽ được coi như có kích thước [2, 3, 4, 4] trong quá trình phép toán, mặc dù dữ liệu thực tế của nó không thay đổi, chỉ được lặp lại.\n",
    "\n",
    "Trong trường hợp lỗi mà bạn đang gặp phải, có vẻ như một trong các tensor đầu vào của node `Add_44` có trục với kích thước 319, trong khi tensor kia có trục tương ứng với kích thước 320. Điều này không phù hợp với quy tắc broadcasting vì để thực hiện broadcasting, kích thước của tensor nhỏ hơn trên trục cụ thể đó phải là 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để làm rõ vấn đề bạn đang gặp phải trong quá trình broadcasting ở node `Add_44` trong mô hình ONNX của bạn:\n",
    "\n",
    "1. **Tensor Đầu Vào của Node `Add_44`**: Node `Add_44` có ít nhất hai tensor đầu vào để thực hiện phép cộng. Trong trường hợp của bạn, có vẻ như hai tensor này có kích thước không tương thích trên một trục cụ thể.\n",
    "\n",
    "2. **Kích Thước Của Các Trục**: Một trong các tensor đầu vào có một trục với kích thước 319, trong khi tensor kia có trục tương ứng với kích thước 320. Điều này tạo ra sự không tương thích vì kích thước của mỗi trục trong mỗi tensor đầu vào phải giống nhau hoặc một trong chúng phải có kích thước là 1 để có thể thực hiện broadcasting một cách hợp lệ.\n",
    "\n",
    "3. **Ý Nghĩa của Lỗi**: Lỗi bạn nhận được chỉ ra rằng có sự không phù hợp trong việc thực hiện broadcasting giữa hai tensor đầu vào này. Trong ONNX và hầu hết các thư viện xử lý tensor, để broadcasting có thể xảy ra, kích thước của tensor nhỏ hơn trên trục cụ thể phải là 1. Nếu không, tensor nhỏ hơn không thể được tự động mở rộng để phù hợp với tensor lớn hơn.\n",
    "\n",
    "4. **Giải Pháp**: Bạn cần đảm bảo rằng kích thước của các tensor đầu vào cho node `Add_44` phù hợp với nhau. Điều này có thể đòi hỏi việc chỉnh sửa cấu trúc mô hình hoặc xử lý trước dữ liệu đầu vào để đảm bảo rằng chúng có kích thước tương thích.\n",
    "\n",
    "Nói cách khác, bạn cần kiểm tra và chỉnh sửa kích thước của các tensor đầu vào trước khi chúng được đưa vào node `Add_44` để đảm bảo chúng tương thích với nhau hoặc thực hiện các bước cần thiết để cho phép broadcasting diễn ra một cách hợp lệ."
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add_44: Node Properties, inputs: A name: tmp_7 và B name: nearest_interp_v2_2.tmp_0\n",
    "- Connection Properties: name tm_7, input form node Add_41, output: to node Add_41. \n",
    "- Connection Properties: name nearest_interp_v2_2.tmp_0, input form node Resize to node Resize_2, output: to node Add_41. \n",
    "\n",
    "- Add_41 Node Properties: output: name tm_7\n",
    "- Resize_2, scales<4> Node Properties: (type Resize) name Resize_2, Attributes: mode nearest, Outputs: name nearest_interp_v2_2.tmp_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa trên thông tin bạn cung cấp, hãy phân tích quá trình dẫn đến lỗi ở node `Add_44` trong mô hình ONNX của bạn:\n",
    "\n",
    "1. **Node `Add_44`**:\n",
    "   - Đầu vào A: Tên `tmp_7`, đến từ node `Add_41`.\n",
    "   - Đầu vào B: Tên `nearest_interp_v2_2.tmp_0`, đến từ node `Resize_2`.\n",
    "\n",
    "2. **Node `Add_41`**:\n",
    "   - Đầu ra `tmp_7` được sử dụng làm đầu vào cho node `Add_44`.\n",
    "\n",
    "3. **Node `Resize_2`**:\n",
    "   - Loại: Resize với thuộc tính `mode` là nearest.\n",
    "   - Đầu ra `nearest_interp_v2_2.tmp_0` được sử dụng làm đầu vào cho node `Add_44`.\n",
    "\n",
    "Dựa trên cấu trúc này, đây là những điểm cần chú ý:\n",
    "\n",
    "- **Xử Lý Tensor trong Node `Add_44`**: Lỗi broadcasting xảy ra ở node `Add_44` có thể là do kích thước không tương thích của tensor `tmp_7` và `nearest_interp_v2_2.tmp_0`.\n",
    "\n",
    "- **Kích Thước Tensor sau Resize**: Vì `nearest_interp_v2_2.tmp_0` là kết quả của một hoạt động resize, có khả năng rằng kích thước của tensor này sau khi resize không khớp với kích thước của tensor `tmp_7`.\n",
    "\n",
    "- **Kiểm Tra Kích Thước Tensor**: Bạn cần kiểm tra kích thước cụ thể của cả hai tensor đầu vào này trước khi chúng đến node `Add_44`. Nếu có sự không khớp, bạn cần đảm bảo rằng chúng được điều chỉnh sao cho phù hợp với nhau hoặc rằng kích thước của tensor nhỏ hơn phải có trục với kích thước là 1 để broadcasting có thể diễn ra một cách hợp lệ.\n",
    "\n",
    "- **Điều Chỉnh Hoạt Động Resize**: Nếu lỗi xuất phát từ node `Resize_2`, bạn có thể cần điều chỉnh cách thức resize tensor để đảm bảo kích thước sau khi resize phù hợp với tensor `tmp_7`.\n",
    "\n",
    "Để giải quyết vấn đề, bạn nên kiểm tra và so sánh kích thước của tensor `tmp_7` và `nearest_interp_v2_2.tmp_0` và đảm bảo rằng chúng có kích thước tương thích hoặc điều chỉnh quá trình xử lý tensor để đạt được sự phù hợp cần thiết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Name: Add_41\n",
      "Input Tensors: ['conv2d_114.tmp_0', 'tmp_6']\n",
      "Output Tensors: ['tmp_7']\n",
      "Node Name: Resize_2\n",
      "Input Tensors: ['tmp_9', 'Constant_50']\n",
      "Output Tensors: ['nearest_interp_v2_2.tmp_0']\n",
      "Node Name: Add_44\n",
      "Input Tensors: ['tmp_7', 'nearest_interp_v2_2.tmp_0']\n",
      "Output Tensors: ['tmp_10']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model_path = 'model/model_det.onnx'\n",
    "model = onnx.load(model_path)\n",
    "\n",
    "# Function to print information of a node\n",
    "def print_node_info(model, node_name):\n",
    "    for node in model.graph.node:\n",
    "        if node.name == node_name:\n",
    "            print(f\"Node Name: {node.name}\")\n",
    "            print(\"Input Tensors:\", node.input)\n",
    "            print(\"Output Tensors:\", node.output)\n",
    "\n",
    "# Print information for specific nodes\n",
    "print_node_info(model, \"Add_41\")\n",
    "print_node_info(model, \"Resize_2\")\n",
    "print_node_info(model, \"Add_44\")\n",
    "\n",
    "# Compare sizes of tmp_7 and nearest_interp_v2_2.tmp_0\n",
    "# You will need to extract these tensors from the model and compare their shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triển khai .onnx bằng cmd  (cách anh Tú) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict detection\n",
    "%cd /content/PaddleOCR-Vietnamese\n",
    "!python ./tools/infer/predict_det.py --det_algorithm=\"SAST\" --use_gpu=True \\\n",
    "                                    --det_model_dir=\"./inference/SAST\"  \\\n",
    "                                    --image_dir=./train/vietnamese/unseen_test_images/im1520.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
