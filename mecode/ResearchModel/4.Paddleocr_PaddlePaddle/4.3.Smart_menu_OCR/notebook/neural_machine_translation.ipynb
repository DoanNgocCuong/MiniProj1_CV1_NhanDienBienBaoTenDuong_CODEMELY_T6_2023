{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGFTkuRvzWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3521a1e-45d4-4486-a264-0d68a3b72839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-text==2.8.* in /usr/local/lib/python3.7/dist-packages (2.8.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.47.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.26.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.1.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1fvjtZxFxls4KSQtoplP_Xoq-5OsEM7on\n",
        "!gdown --id 1zwSQE4s_vrY0q7dQWAvcBvLC6wfv3OBx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lnXxvLaazBF",
        "outputId": "053a9224-cae8-4fb0-9589-136af9b3557b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fvjtZxFxls4KSQtoplP_Xoq-5OsEM7on\n",
            "To: /content/food_en_dict.txt\n",
            "100% 336k/336k [00:00<00:00, 118MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zwSQE4s_vrY0q7dQWAvcBvLC6wfv3OBx\n",
            "To: /content/food_vn_dict.txt\n",
            "100% 334k/334k [00:00<00:00, 85.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, encoding=\"utf-8\", mode='rt') as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return data.split('\\n')"
      ],
      "metadata": {
        "id": "ypKjrUera8K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "outputs": [],
      "source": [
        "targ = load_data(\"/content/food_en_dict.txt\")\n",
        "inp = load_data(\"/content/food_vn_dict.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH_dPY8TRp3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801fb504-8724-447c-ff66-2f1872997935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(inp[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqHsArVZ3jFS"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a3eede-5dd2-4418-af7c-ef84194a7859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'sashimi tr\\xe1\\xbb\\xa9ng t\\xc3\\xb4m'\n",
            " b'c\\xc6\\xa1m chi\\xc3\\xaan mu\\xe1\\xbb\\x91i \\xe1\\xbb\\x9bt'\n",
            " b'\\xe1\\xba\\xbfch + x\\xc3\\xb4i'\n",
            " b'b\\xc3\\xb2 cu\\xe1\\xbb\\x99n kim ch\\xc3\\xa2m' b'udon t\\xc3\\xb4m tempura'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'ebiko masago' b'fried rice salt chilly' b'frog + sticky rice'\n",
            " b'beef and enoki mushroom rolls' b'shrimp tempura udon'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UREvDg3sEKYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5f969e-d0f3-42e3-af13-790cf18be51c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Todavía está en casa?\n",
            "[START] ¿ todavia esta en casa ? [END]\n"
          ]
        }
      ],
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3881ea45-cf8f-4384-fadf-4ae6710c34bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', 'ca', 'tra', 'bo', 'sua', 'nuong', 'chien']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGjIFjX8_Wp"
      },
      "source": [
        "That's the Spanish `TextVectorization` layer, now build and `.adapt()` the English one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlC4xuZnKLBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037a8619-0638-4a8f-8154-a8d4075c3c39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'with',\n",
              " 'fried',\n",
              " 'tea',\n",
              " 'grilled',\n",
              " 'rice',\n",
              " 'milk']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KZxj8IrNZ9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a9e7ab-a622-4d36-ec45-3f50e2cc9966"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[  2, 102,  15,  12,   3,   0,   0,   0,   0,   0],\n",
              "       [  2,  13,   9,  20,  42,   3,   0,   0,   0,   0],\n",
              "       [  2,  76, 274,   3,   0,   0,   0,   0,   0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98g9rcxGQY0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e7e2d7e2-77f6-4df5-e776-f0e2a7054ed7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] sashimi trung tom [END]        '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot0aCL9t-Ghi"
      },
      "source": [
        "The returned token IDs are zero-padded. This can easily be turned into a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jx4Or_eFRSz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "f6305cb8-5ff1-4d08-a96c-ea573442e377"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de7ScVZnmn7eqTs7J/eR6SE6ukAtXQQgJrQiIbatIm+4eG1DHCTY9me6B1TPa9oDaC9S2e+F0j8AsGJy0oIANEVEb2tFGRBAvRCBcEiCBJJiQk/s9OUlIUlXv/FHfcRUhIfs5qcu3v3p+a511TlU9tWtXsuv5dr177/c1d4cQQohskWt2B4QQQtQembsQQmQQmbsQQmQQmbsQQmQQmbsQQmQQmbsQQmQQmXuTMLOLzKyn2f0QIibM7HEz+/Nm9yMGZO41wMx6q37KZra/6vYnmty3330YkgtKuapvPWZ2v5md28w+imxhZqvN7KCZjT7s/ufMzM1sSnN61lrI3GuAuw/p+wHwOoA/rLrvX5rdv8NYn/RzKIDzACwH8Asze19zuyUyxm8BfKzvhpmdAWBQ87rTesjc64iZtZvZzWa2Pvm52czaj6L9KzN72cwmJM/7JzN73cw2mdnXzWxgorsomXH/tZltNrMNZvYptm9eocfdrwfwDQBfTdo3M7spaXu3mS01s9OP599BtCT3APhPVbfnAbi774aZfTiZye82s7Vm9sWqxzrM7Ntmts3MdprZ02bWdfgLmNk4M1tiZn9TzzcSKzL3+vIFVGbHZwE4E8BsAH97uMjMrgdwJYAL3b0HwI0AZiTPmwagG8D1VU85AcDw5P6rANxmZiOOo5/fB3C2mQ0G8AcALkhefziAywBsO462RWuyCMAwMzvFzPIArgDw7arH96Ji/p0APgzgL83sj5LH5qEy9iYCGAXgLwDsr27czKYC+DmAW939H+v5RmJF5l5fPgHgy+6+2d23APgSgE9WPW5m9jVUDPW97r7FzAzAfACfdvft7r4HwD+g8uHo41DS7iF3/xGAXgAzj6Of6wEYKh+0Q6iEbE4GYO6+zN03HEfbonXpm72/H8AyAOv6HnD3x919qbuX3X0JgPsAXJg8fAgVU5/m7iV3X+zuu6vaPRXAYwBucPcFjXgjMVJodgcyzngAa6pur0nu66MTFSO/3N13JfeNQSU2ubji8wAqxpuvet42dy9W3d4HYMhx9LMbgAPY6e4/M7NbAdwGYLKZfR/AZw/7cAkRwj0AngAwFVUhGQAwszmofEM9HcAAAO0Avlv1vIkAFppZJyoz/i+4+6Hk8U8AWAnggXq/gZjRzL2+rAcwuer2pOS+PnYAuBTAN83s3cl9W1H5Cnqau3cmP8OTRdB68ccAnnX3vQDg7v/b3c9BZYY0A4BimoLG3degsrB6CSqhv2ruBfAQgInuPhzA11GZxCD5Rvoldz8VwLtQ+YxUx++/iMrn5N4k5COOgMy9vtwH4G/NbEyyLex6vDnuCHd/HJWZyPfNbLa7lwH8M4CbzGwsAJhZt5l9oJYdSxZOu83sBgB/DuDzyf3nmtkcM2tDJS76BoByLV9btBRXAbi4b+JQxVAA2939DTObDeDjfQ+Y2XvN7IzEuHejEqapHoOHAPwpgMEA7jYz+dgR0D9KffkKgGcALAGwFMCzyX1vwt0fAfBnAP7NzM4GcC0qXzsXmdluAD/F8cXUqxlvZr2oxOmfBnAGgIvc/SfJ48NQubjsQCWMtA2AFqxEv3D3Ve7+zBEe+q8Avmxme1CZ9Nxf9dgJqIRcdqMSq/85KqGa6nYPAvgTAF0A7pTBvxVTsQ4hhMgeutoJIUQGkbkLIUQGkbkLIUQGkbkLIUQGScUhpgHW7h0YHKQtjgnT9VHYuo/rjBaYM8ce7Njq7mOa8dqjR+Z9ysS2Zrz0cfHqEuX4ioG3G9upMPcODMacwKSEtpP7oORHDaP0xe07grWF8Sdwba9bf2yRqDk/9QfWHFtVH6ZMbMNTD09q1sunkg+MP7PZXcgMbze2g8zdzFYD2AOgBKDo7rPMbCSA7wCYAmA1gMvcfUeSG+UWVE6l7QNwpbs/ezxvoJr82NHHFlWx5YNTOP15pWDtjPlPUW2L9JGmsR0zMuz0wczc3+vuW6tuXwfgUXe/0cyuS25fC+BDAKYnP3MA3J78rg1k2GTkXZwBj/p2+GlmHdvMDOkY20LUkOMJy8wFcFHy910AHkflAzAXwN1eOR21yMw6zWxcrTILFjds5J5AHlzz0kGufZFFmjK204Rm4vETau4O4Cdm5gD+b5Jms6tqUG9E5RgwUMkwuLbquT3JfW/6AJjZfFQyIqIj0gIt+c5OSu/736D05QOcXvSLuo7tSd2pWNaieXj9C83uwu/QhaZ/hI688919XZLI6hEzW179oLt78uEIJvkQLQCAYTYy+LlWIBdUu7hNEsyiZ2nnTqptkUrqOrZnndkR5fYrGWr8BJm7u69Lfm82sx+gUlFoU99XUjMbB2BzIl+HSi7mPiagKkn/8ZIf/5ZqW2/La1dxOxUm3aAdLa1Emsa2ELXkmOaelF7LufueqjJsX0YlF/M8VBLuzwPwYPKUhwBcY2YLUVls2lXLmGRpLFdNbvL/20PpN1/9rmDtCfcto9ouEdssRf1J29hOE/UMy+hbQWMImbl3AfhBUhWoAOBed/93M3sawP1mdhUqqWEvS/Q/QmWr2EpUtovRxZvfjvz6rccWVeEjuX3uXb8MD7XIrKMnVWM7ZmTY6eOY5u7ur6FS3Pnw+7cBeMvJo2QnwdU16d2RO8TpezZR8tyA8Ji+tkLGTerGthA1JLqlfHYrZH4IV52uuCu8VGhuELfLp7yPTIUgRCQwYRzN8htDdObOmrUf5Pat5wYMCNaWya2NhWknUvriytcovRAxwMbzdTHoH9GZe6m3l3vC75ED48n6LSTJrEUsyFDjJzpzZ8kt5na0KI4uhMgCmTf3bf/xHEo/eEMxWDtoKbcnvtijLdEiDrQVMn6iM3fLhyf2AoDR33uZa39oeExfZi2ESCvRmTtL6dQp3BPqGHMXIhY0u46f+MydzPLIxtxzxI4WLZCKrKIdLfETnblv/dS5lH7P7++l9FMu18xdCJl1/ERn7qO/+TSlH/Nt8i22dwRLlZJXZBXN3OMnOnO3nFH6f135C0r/ke5ZlF6ILCKzjp/ozD03giuQMXcSVwWtMG1ysFYxd5FVNHOPn+jM3fdy+Vm8FF7wGpBhi2wi8209ojN3Nv0Am4umvH9/sJatCoWTudwy5Re4PfpCHI00lc1j0YWpf0Rn7jQF7i0yh6Rs5lSqbV+ubwVCiMaQfXMnwzK5seE1V8sr11Bta3eNEJqJN4rMm7sfOMDpt20P1pbf4NoWQohGEZ25s3Hu3NChlJ5ZgLVD4UnGAMBy3D93mcxFL0QMaCdOY4jO3HNsnHvDFkrPxNzz3SdQbRfXrKX0QmQRmXVjiM7cbXt4GTwAICuuAoVwc5dZC1FBhp0+ojN3toZqoXs81/46Lke7EFlEZh0/0Zk7vbfcuHQFOeWWEUJx8QwQnbnDuUJ4bEGNQtfYYG15k8xdCJFOojP3fCeXWwZEZSWAi6OzVaH83NMpPRbFe6pQtBYqy5c+ojP30i5yQXX7Du4FiG8Gzp2PklmLaJChxk905s6GZcoXnEXp255fFawt7dpFtS1ELCjmHj/RmXv3rwdS+mfuC18gBYDurV3B2gPvmUm1PXgl9y2iuHwFpReiWSgskz6iM/ee87iUv93DXqL0zGy8fSg36GTWQsisG0V05p7raOeeMGkcJS/sHhYufn0z1fb+D3D1X9se5koKChEDCvk0hujMnaW0dDmlz58yI7ztZa9Sbbet30DphYgFGXD6iM/cyUNJBSKFLwCU1/QEa5kLAcBfDISIBWY2rgtBY4jO3Pe/j9srvvD/3ETp5018d7hYZi0yigw4fqIz98EvcLlfrjr/CkpfGB+exreoMIvIKIqLx0905l7eyC1ilsmc64Vx4VshhRAirQSbu5nlATwDYJ27X2pmUwEsBDAKwGIAn3T3g2bWDuBuAOcA2AbgcndfXasOswUscgMGUHrfV78C2a/9/SxKf9L1z1F6JTLjScu4jp00FeDWt4gKzMz9vwFYBqBvr+BXAdzk7gvN7OsArgJwe/J7h7tPM7MrEt3lNeux5Tg9WSAbE8Jn7mxumek3/5bSl3Pc4rHoF+kY10LUmCDnM7MJAD4M4O8BfMbMDMDFAD6eSO4C8EVUPgRzk78B4AEAt5qZuTtdN+OIkOkHjJy5Y214vvhcJ7EnHnwuelFfUjWuWwjNrBtD6LT2ZgD/A0BfQdJRAHa6e19AuwdAd/J3N4C1AODuRTPblei3VjdoZvMBzAeADgwK7/CUycFaACiuXkPpyxeeHazN/fxZqm2ROmo+roE3j+1J3dEta/ULGXb6OObIM7NLAWx298VmdlGtXtjdFwBYAADDbGTw7Ic1azbmXugh8r9M6D62pgofwRXrZg9giXDqNa6BN4/tWWd2tMTMXrll0kfItOLdAD5iZpcA6EAlNnkLgE4zKySznAkA+qpirAMwEUCPmRUADEdlAaomHLh0NqUf+MgSSu8d4Yuk4+7lim/3zOEKh4i6kqpx3UrIrBvDMc3d3T8H4HMAkMxwPuvunzCz7wL4KCo7C+YBeDB5ykPJ7SeTx39Wy7hkx48XU3obFB7yAYDSS+EHk3rmUE2LFJG2cZ02ZMDxczwBwWsBLDSzrwB4DsAdyf13ALjHzFYC2A6AO0V0DHKkWe/+4GmUfvB3F1F6kTmaMq6FqDWWhsnHMBvpc+x9YWJ2KySJEdsPvcSWYhLN4Kf+wGJ35w4Z1IhZZ3b4Uw9PasZLNxTN9JvD243t6Jby9/0JF3Nv6+UMWGl2hZBZZ4HozH3o8u3cE3o2UfIS8c2A3YmjE6QiFrT7JX6iM3dmwRMAyhe8k9K3vbg6WGtkiEjmLoRoFNGZO71vfXl4fnYAKO4IL7OXa+P++QonTuH68tpqSi9EDCjjZGOIztzZLI/lLdxWZGZBFWRuGZm1EDLrRhGdufdexi2otu8kF1R/Er6P3mZMpdrGCy9zeiGE6CfRmfuQ75D70Mm4OJPPvSizFgKAZuNpJDpzZ2Puh95zBvcCj3InYIXIIjLr+InO3Nn87G2/fInS57rHB2vLozu5ttdzVaTY96qUwqJWpKn4BosuTBXiM3eS3OiRlN5794ZrN3J76Is60SqEzLdBRGfufuAA94SOdkpe3hSe6ZGtxKR0BUKIRhGdue/7CJcipHc8Z8Bd39gQrH31H8+i2p7xN89T+j0f4dpX0jMRA/UO+eibQYXozP3bt/wvSv+fJ51P6ZkiftP+ijNTrkCgzFrUDhle6xGduf+Xme8nn7GfUudPmRGsLS3jUiEI0Sw0W249ojP38n7OrNl97uVXV3HtCyGoi4cuBI0hOnMvzJxG6b3AmXvp5ZXBWrZwSHnfPkovhBD9JTpzL776GqXPkbtlDl4SvmA76Lm1XF+6x1H64gp9ixDZQ4nDGkN05l6Y1E3pi69zRak7Hgnf0VImt0KW14fvxBEiq8isG0N05s6adX7YUEpf7u0N1vrBg1TbQmQVGXb6iM7cmcReAFDetoPS5yeEpx8oruHCMkII0SiiM3eWMjm7LhPfDHLtHVzbqsQkMop2y6SP6Mzd95FbIUmo6kpMYQ8hhGgg0Zl7vQ2VnekLITQbTyPxmfvBQ83uwe/Y+Ol3UfoTbvp1nXoiRHNRWCZ9RGfu5Te4rJBsEWtm5i6zFllFBhw/0Zm7F7mZu5PpB7bND5+Nj77jN1TbLFZoo/RasBW1QsU64ic6c2dzxRgZo+96LLwAR72Lbyj/u4gFGWr6iM7c88OHUfrSrt2U3gdyNVqFECKNRGfuTibfoi8GS5ZReiGyiGbi8ROduZcPFSl9gayhanv2BGu97FTb9VzcFaKWpCnmrgtN/4jO3NmZeHEll0WSiemzNVSFEKJRRGfuZWJmDfA513MjR4T3ZXN4MW2AXyBVAW4hlCK4v0Rn7mwo5OD5p1L6jidfofQMMl8hZL6N4pjmbmYdAJ4A0J7oH3D3G8xsKoCFAEYBWAzgk+5+0MzaAdwN4BwA2wBc7u6ra9Vhm306pR/4Kje7LpLfDES8pG1spwkZcPyEzNwPALjY3XvNrA3AL83sxwA+A+Amd19oZl8HcBWA25PfO9x9mpldAeCrAC6vVYdzK8g0u2Roo3DilGBt8bXVXF9E2kjV2E4TCoXEzzHN3d0dQF8Fi7bkxwFcDODjyf13AfgiKh+AucnfAPAAgFvNzJJ2jpvSjl21aObobNkaLC2cNJVqurjqt2xvRB1J29iOGeWWSR9BMXczy6Py9XQagNsArAKw09379iX2AOirf9cNYC0AuHvRzHah8vV262FtzgcwHwA6EL7oye6WKc+YSOn9qaXBWpl1/NR7bE/qjm5ZC4AMOAsEjTx3LwE4y8w6AfwAwMnH+8LuvgDAAgAYZiODZz7Wzp0gzW/ayXVs5rRgaXkQeZq1zMmNXICdcGdPsHbN7L1cZzJKvcf2rDM7opzVp2mfe73J6oWMmla4+04zewzA7wHoNLNCMsOZAKCvhNE6ABMB9JhZAcBwVBafakJpK9dUfupkSu9bwtsvb+dK+NWbNbOb3YN4ScPYjpmsGmTMhOyWGQPgUDL4BwJ4PyoLSY8B+CgquwrmAXgwecpDye0nk8d/VsuYJJspsbhqda1e+i0UJnMhH5DpioubNnPtC4q0je2YqedMXxeO/hEycx8H4K4kNpkDcL+7/9DMXgaw0My+AuA5AHck+jsA3GNmKwFsB3BFLTvMHslns0LinPB98eyudSaeLxpCqsZ2qyCzbgwhu2WWAHjnEe5/DcBbAgHu/gaAP61J745AYVwXpS+u30Dp8y+HL5KW9nJJzES6SNvYFqKWxLeUX+QSh+XOPo3S25qNwdr8AC5EVEpZjF4IkV2iM/dXrg3fzQIAM774IqXXCVUhFDrJAtGZ+0mf5Urb2YwTKf3BE8N3wg348dNU20LEgk6oxk905p4fzGV59HXhYRYAGPAqmSJYCCFSSHTmXia3E/q5XFbI3AsrwvtCVoVi0w+z7QvRLLQVMn1EZ+5ePETpGbMGAD8QfvHIDRzI9YXIFQ8AKHFHWm1weH+0uCtiod6nZbN68YjO3HsvP4/Sd/7ydUpfXLc+WOv791Ntl3vWHVt0PBx4o77ti5Yhq4bXSkRn7kMf4BYxX/kn7kz+jOvDd8ts/SiXW37EN5+k9EI0C4VZ4ic6c/dzOUOdedsmSs9shZRZi6wiA46f6Mx92zsGU/pRC1onu50QR0Nm3XpEZ+6j/nkRpWeLTOeIfPE7PzCTarvzhy9R+pIOVIkaEXMKX12Y+kd05n7NCq6A9a3TplN6ZhfJ0Pu4C43KY4tmIYNsPaIz99tmcrUUrJDj9ES+GHZrY7Heu2WEOAppmrnrQtMYojN3GGnWbFiG2Lu+7HMTqLanXy1zF0I0hujMPTeEW1At7dpN6cvbwveKT79aRXhENtHsOn6iM3dM4PK55yaPp/TlF16m9EIIkUaiM3dfsYbSl3VqUwjNxFuQ+My9VN89Jzb7jGBt7hUutYGTJQJzQ4dQ+uLmLZRetA5pWlCtN7qQVYjO3PPjubCM79jFvcDKnmBpmSyzxyY9K5O5a4SIAZlvY4jO3Mtbt3NPIDMrlnVwSAgaGXb6iM7c/SA3+80TJ04BYMu8s4O1nSu43PL5xxZTeiFigQn76ELQGOIzdzK0USTzlo+9d0l4X8j4f/k8blDnDnDvFa+sDu+LCoGIJpG2+H9WLzbRmXu+s5PSs/vcQZxQLW/v5dpexA1qLqAkRPPIqkHGTHTmXu7dS+lzHe2UXhWKhBBZIDpzZ8MylrM69USI7KKZePxEZ+6FsWMoPbv3m9nn7k9zKXzhCrSIOFAlpviJztxRILtMJhrD4vD0A3kyz03xrGmUvu1lsv7rNuW6EelHBa8bQ3TmvvOCyZR+yMINlL50fvhWSP/5s1Tb9ovnKH2RUgvRPGSo6SM6cx+ykCuQwc7cB6wJn/3KfIUQaSU6c2cpnDSF0hdXra5LP4QQopFEZ+6FUaMovW8h49Ba9BRCYZYMEJ25YyR5iGnFKkqfHxKeiZFN7HXg/eHxfAAY+OSrlL60i0ySJsRRSNspUgZdmCpEZ+7lddwCaf60GdwLrFkfLPWyU013/Iz7wJTIFMFCZBGZdf+IztzfuPA0St/+yPOU/uDF4QNpAGnW9DZOmbsQop8c023MbCKAuwF0AXAAC9z9FjMbCeA7AKYAWA3gMnffYWYG4BYAlwDYB+BKd+f2DL4NW98RnvsFAEa0k6GQf/1NsJabt/Ona0V9SdvYThOaLcdPyFSyCOCv3f1ZMxsKYLGZPQLgSgCPuvuNZnYdgOsAXAvgQwCmJz9zANye/K4N5HonY9ai5UjX2K4jMuvW45jm7u4bAGxI/t5jZssAdAOYC+CiRHYXgMdR+QDMBXC3uzuARWbWaWbjknaOm0nfC4+JA0CpwM30md0yls9TTZcVZkkVaRvb9SRNC6S60DQGKghsZlMAvBPAbwB0VQ3qjah8tQUqH461VU/rSe570wfAzOYDmA8AHRgU3Ifyxs1Ml5HvInPRTAzX51eEl+QDgLLSA6SWeo3tSd3RLWuJjBA88sxsCIDvAfjv7r67En6s4O5uZlQI2t0XAFgAAMNsZPBzcwMHMi8DJ+ucMjnXdUI1G9RzbM86s4NdmkkFml3HT5C5m1kbKoP/X9z9+8ndm/q+kprZOAB9U+p1ACZWPX1Ccl9NoJNjkekH8kOHhjc9YADXl4EdlLzYU7N/NnEU0jS204TCOPETslvGANwBYJm7f63qoYcAzANwY/L7war7rzGzhagsNu2qaUySNOvC2NGUvrgpPOzDHHgCgJLCMqkidWO7RZBZN4aQmfu7AXwSwFIz69s0/nlUBv79ZnYVgDUALkse+xEqW8VWorJd7FO17HCOnf0SZg0Axd+fFawtLOVS8ubK3FYf1TmtO6ka260C+61AF4P+EbJb5pcAjlbO6H1H0DuAq4+zX0cl1zmc0w8fxul/HZ7PvSjzjZq0je2YkQGnj+iW8ovruW/BBy6dTenbf/gUpRcii8is4yc6c893conDBm7gZtd2+sxg7b6p3LeI9n/ThUPEgcrsxU905l7es4fSr/lDLiwz+e/CT7S2v1ii2hYiq8iw00d05u4lzlAnfYmr3LTi5vAwjg/jdrqf8nnu0FNxw0ZKL0Sz0Ew/fURn7oUTp1D6gxNHUvqbP3xPsPbWadOptnXoSWQVGXD6iM7ci7/lth8O2MWFcW6dHh5zp7OYCSFEg4jO3HNtXJeL23dQ+sK4rmOL+tomd+4IIUSjiM7c6cyK5IlWHArPuc7u3Cnt3Mn1RYhIYGLuCuE0hujMvXAyGed+hauhWpo8LlibX7uJalsIIRpFdOZefp3L05TraKf0tv9AeF/29FJtM0nJAKDUu5fSM7nohWgW9U5Kpm8GFaIzdzYTo43mdsugFJ6htXIanYAs7iGzFkJm3V/iM/cuLsujb9xC6Uu7w3fX5MgLjWLuQsisG0V05l4eROZQnzbx2JpqFr8Y3pcDb3BtCxEJMuD4ic7c8cpqSr7nkndQ+sHPhu+uyZ/B7IkHSkuWUXohmoVOnMZPfOZOMvyxFZTeiRTBvnIN2x0hWh7lc28M0Zl7eT8XCsmNIPeirw/P55IfwWWFhPK/CyGzbhDRmTtbNq/MnlDtDt/nrhqnQlSQYaeP6MydLZtX6BrLtb8uPKXApgdPodru/jOy5J9qropIUIw+fURn7uz2Q9+3n3sBYm9511xugVRZIUUsyFDjJzpzP/BebtDl93OWmnviufC2hwyh2i6fOpXS29KVlN6JvDvFC86i2m771VJKn5vYHd6XVb+l2hb1p96nSMWRqeVFNTpz3zOhjdKP+tazlJ48c8q1/RRnkPXsS/6xxZSePStblmGLo6BvBY0hOnMfeSdXWSl/0hRKX1y1OljrZaUHEEKkk+jM3XJG6Uur11J6Jl98WVsbhQCg2Xgaic7cc4MGUXragPPhC7Z7P3oe1fTgB7hvHULEgvK5p4/ozJ1Og0uSK4T/kwx/gssVXz77NE7/7EuUXogY0AnVxhCdubNbIdm0uTawI1hb3MxlnASrFyISZMDpIzpz92J4GTwAdJk9L2o3uhAifuIz91KJ0tscLhRia8Nn14UxXCqE4patlF6IWFDMPX1EZ+6FSRMoffGp8PzsALDvA+cEa9t/+jzVthBCNIrozL28dTv3hDlnUPKBa3cFa1/9n7Ootk/6zJOUXggh+kt05v7K106n9DOuCU8nAAAlIqZ/0meopoWIBoVO4ic6c5/5ae4I/6ELuUpM7Ss2BWvLm7gYug3gUieU9oTXcxWilqQpt4wuNP0jOnMv7+eyPLY/v5rS1zXNrmquikiQocbPMc3dzO4EcCmAze5+enLfSADfATAFwGoAl7n7DjMzALcAuATAPgBXujuXuesY5Du5ykpFsliHaB3SNraFqCUhM/dvAbgVwN1V910H4FF3v9HMrktuXwvgQwCmJz9zANye/K4ZbGiDXVDNL1sd3pdBA6m2ixvCS/iJhvAtpGhspwkV34ifY5q7uz9hZlMOu3sugIuSv+8C8DgqH4C5AO52dwewyMw6zWycu4eXNzoG9KnQLWSY5dRpwVI6Ja/MPVWkbWwLUUv6G3PvqhrUGwF0JX93A6hOw9iT3PeWD4CZzQcwHwA6EJ4MjC2QgYnjKXlxRHhf7FdLuL6IGKjp2J7UHd2ylsgIxz3y3N3NjJ7EuvsCAAsAYJiNDH5+aS+X5bGwfSelXz0v/NTp9BXkCVWy/qtoLrUY27PO7KhnzRUhjkp/zX1T31dSMxsHoM+11gGYWKWbkNxXM/KDyZS/e3op/dTPhaflLZJJyUQUNG1sx4zi6Omjv+b+EIB5AG5Mfj9Ydf81ZrYQlcWmXbWOSbKLmBg7ktO/tCJYWujmQj5ObuMsaadPM2ja2I4ZLcCmj5CtkPehssA02sx6ANyAysC/38yuArAGwKiker8AAAdnSURBVGWJ/EeobBVbicp2sU/VusN1X1AlZuPFdeu5tkWqSNvYThMy1PgJ2S3zsaM89L4jaB3A1cfbqVpSfg83SHNPcOkKRLzEPraFeDuiW8pnDzEVVoWnEwAAHzkiWKuwicgqqpYUP9GZu5ELqqWNnLnnp00N15a4BVV/4wClLytdgYgExdzTR3TmXlzPHQQqzDiR0vu68PZLvdxOHCGyigw4fURn7p9dyWWFvOmcYZRehi2EzDoLRGfuN593IaUv7SRL2xE1V9k992yJQDYDphC1Qil/4yc6c999QXjuFwBo6w2PoQNA28NPB2s1yxdZRYYaP9GZ+6DvP0Xpd1zJJe4L3ysjhBDpJTpzz48YTulH3vMMpVciECFEFojO3DF+LCV37UUXQmGWFiQ6cy8vf62u7RdOnh6sLS4Pz0MjRDPRAmnrEZ2556dNofT7pnInWvHj8AVVIbKKDDh+ojN37+ES8Q0i87lj0oRwbZmL0JfJJGa50WRGy2IxXKrc8uJtSNNMv95k9UIWnbnbSG4mvv/kEyh920/CF2C3/uW7qLZH386l/y4r66TIIFk107QRnbmXt26n9O2/4GbLe/84fOvkkHXhM2UAKIwhKzdtIQ9gCREBSkrWGKIz9xx5KrT3XSdR+qEvhhtqccUqqm3uUiBEPMiA00d05s7GuQf//BVKX9wZHqPPDSJL/u3nsjxazig9kzqBbZtNnZCWtkVjaKUYfT2p5UUyOnMvkvvWCydNofS5k5gFVS7lb2E9F2ZxskRgaeny8LaploWIB32LqBCdubMUV62m9Bcv3ROs/dnpg6m26XLa2tEiIkGGmj7iM3eixikAFKZx+dwfPzd8q+W+/8AN6EHfW0TphYgFJiyjC0FjiM7c/fyzKH15MRdz94MHg7UyayEqyLDTR3Tmbr9aQunZUEiuoz1Ymx9Lbm1cs5bsjRBxoJl7+ojO3AtEAWuA34lRInbLYDO3QGqFNk5P7mgpE986hGgW9d5Zo4tHhejMna1OZG2coRYmdAdrixO5mTsWcSUC82O7KH15PZeaQQiRXaIz99zYMdwT2jlz9/WbwsU9XDoBlqLMWkSCZsvpIzpz9927Kf3rf3EKpe/+h5WUXogsIrOOn+jMnT2hOvmbXP73IlMgm6wKVVLhEBEJ9YyL68LRGKIzd9+3j9LbAC4skxswIFhb2rGLalsIIRpFdOZePpsLs9gecgF2DLEb56VXqbaFyCqajaeP6Mw9v4/b7rd19ihKP/ppLqWwEEKkkejMvbRkGaUfsTQ8hg4AvXPPDdYO3cYVAinv4haDy2QISohmoRh9+ojO3NmDQK9/IdysAWDil34drFV+dpFVZKjxE525s4nDpjzAnSJVZnEhRBaIztxzQ4dyT+ghDiUBsHw+WKsiEyKrqBRe/ERn7jZsCKX3Om5XLIziFmt9HJeuoPQil9FSiGahmHv6qIu5m9kHAdwCIA/gG+5+Y80aL3FhmVLvXq59IuxT3MYV3warF6mjrmM7RchQ46fm5m5meQC3AXg/gB4AT5vZQ+7+ci3aL04ic8us30jJc2eeGqwtv1CTtyQiod5jO00oLBM/9Zi5zwaw0t1fAwAzWwhgLoDafADIzIosToRCcgMHUm2zGS1F6qjv2I4Y5XNPH/Uw924A1VUpegDMOVxkZvMBzE9uHvipP/BiUOv1ruzMRH36txdyNABuC0+cpOl9Tq5RO/0a2/lxK8LGdtwQ/98r6tqRBhDF2G7agqq7LwCwAADM7Bl3n9WsvjSSVnmvrfI+j0Qrju1WeZ9APO+VO74ZxjoAE6tuT0juEyJ2NLZFNNTD3J8GMN3MpprZAABXAHioDq8jRKPR2BbRUPOwjLsXzewaAA+jsl3sTnd/6RhPW1DrfqSYVnmvmXufGttvS6u8TyCS92ru9V6hFEII0WjqEZYRQgjRZGTuQgiRQZpu7mb2QTN7xcxWmtl1ze5PvTCz1Wa21MyeN7Nnmt2fWmJmd5rZZjN7seq+kWb2iJmtSH4TJa7ip1XGNaCxndax3VRzrzrO/SEApwL4mJmFn/+Pj/e6+1kx7JEl+RaADx5233UAHnX36QAeTW63BC04rgGN7dTR7Jn7745zu/tBAH3HuUVEuPsTAA6vTzgXwF3J33cB+KOGdqq5aFxnhJjHdrPN/UjHubub1Jd64wB+YmaLk+PpWafL3Tckf28E0NXMzjSYVhrXgMZ2Ksd2dPncI+Z8d19nZmMBPGJmy5NZQeZxdzcz7bnNLhrbKaTZM/eWOc7t7uuS35sB/ACVr+5ZZpOZjQOA5PfmJvenkbTMuAY0tpHSsd1sc2+J49xmNtjMhvb9DeAPAGQ9U+BDAOYlf88D8GAT+9JoWmJcAxrbSPHYbmpYpp/HuWOkC8APzAyo/Jvf6+7/3twu1Q4zuw/ARQBGm1kPgBsA3AjgfjO7CsAaAJc1r4eNpYXGNaCxndqxrfQDQgiRQZodlhFCCFEHZO5CCJFBZO5CCJFBZO5CCJFBZO5CCJFBZO5CCJFBZO5CCJFB/j+QTazxsn3ANwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder model\n",
        "\n",
        "The following diagram shows an overview of the model. At each time-step the decoder's output is combined with a weighted sum over the encoded input, to predict the next word. The diagram and formulas are from [Luong's paper](https://arxiv.org/abs/1508.04025v5).\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define a few constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "###  encoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3SKkaQeGn-Q"
      },
      "source": [
        "Here is how it fits together so far:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60gSVh05Jl6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c25ef7-2d62-496f-9d5f-7daeb7c43b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (512,)\n",
            "Input batch tokens, shape (batch, s): (512, 13)\n",
            "Encoder output, shape (batch, s, units): (512, 13, 1024)\n",
            "Encoder state, shape (batch, units): (512, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "momiE59lXo6U"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf13LubPGjDO"
      },
      "source": [
        "### Test the Attention layer\n",
        "\n",
        "Create a `BahdanauAttention` layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4QMlOp8Gidh"
      },
      "outputs": [],
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYSHqmORgVFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9153ec06-4ac0-45c3-b6b8-c2b91c572b77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "(example_tokens != 0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y7hjPkNMmHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010134ae-5a51-4088-e409-8cda64136780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (512, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (512, 2, 13)\n"
          ]
        }
      ],
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqr8XGsAJlf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d2f6d26d-3abf-464a-967a-dfd1619307f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eil-C_NN1rp"
      },
      "source": [
        "Because of the small-random initialization the attention weights are all close to `1/(sequence_length)`. If you zoom in on the weights for a single sequence, you can see that there is some _small_ variation that the model can learn to expand, and exploit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuzrCdmYlTcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06283568-ce9c-4d5a-96ab-82f6815322b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512, 2, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "attention_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIMwC-f-ZC8N"
      },
      "outputs": [],
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "###  decoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class and its initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUTfYHmfmwKH"
      },
      "source": [
        "The `call` method for this layer takes and returns multiple tensors. Organize those into simple container classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WfSIb2sArRT"
      },
      "outputs": [],
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NChkl2KrnV2y"
      },
      "source": [
        "Here is the implementation of the `call` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay_mTMPfnb2a"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZUMbYXIEVeA"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u6eJBU4GL40"
      },
      "outputs": [],
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\n",
        "example_output_tokens = output_text_processor(example_target_batch)\n",
        "\n",
        "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5hqvbR5FUCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad97eca-815c-4fb8-d6ff-53fb82c6677f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (512, 1, 3051)\n",
            "state shape: (batch_size, dec_units) (512, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Run the decoder\n",
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEZvXZRVPHd6"
      },
      "source": [
        "Sample a token according to the logits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5UY8wko3jFp"
      },
      "outputs": [],
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xTpX44VkzrY"
      },
      "source": [
        "Decode the token as the first word of the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKXTLYu4IV7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21985a5-79c4-4dac-d985-d882c4e7d3cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['makerel'],\n",
              "       ['champagne'],\n",
              "       ['noddle'],\n",
              "       ['vinegared'],\n",
              "       ['miserable']], dtype='<U31')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX1VF9XDJTOM"
      },
      "outputs": [],
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1rs0XL7Y2aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a20dbe0-f1da-4c97-9cd5-5e1cf51241cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['dish'],\n",
              "       ['highball'],\n",
              "       ['pinnata'],\n",
              "       ['tokbokki'],\n",
              "       ['mantis']], dtype='<U31')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that you have all the model components, it's time to start training the model. You'll need:\n",
        "\n",
        "- A loss function and optimizer to perform the optimization.\n",
        "- A training step function defining how to update the model for each input/target batch.\n",
        "- A training loop to drive the training and save checkpoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5AgEBh2S404"
      },
      "source": [
        "### Implement the training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor,\n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlYE68wzXoA8"
      },
      "outputs": [],
      "source": [
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHy6hzStrgjQ"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qs_gsISsYPpY"
      },
      "outputs": [],
      "source": [
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs\n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables\n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGwWHIxLrjGR"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._train_step = _train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VrzgwztXzYJ"
      },
      "outputs": [],
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj3I7VULrk1R"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA6bCske8TXm"
      },
      "outputs": [],
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y5OnZDsB3sB"
      },
      "source": [
        "Test out the `train_step`. For a text model like this the loss should start near:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHe-OudqCFGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb295f7-a794-4956-a1c1-d2a2c9352841"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.02322468471667"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "np.log(output_text_processor.vocabulary_size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwMU9cFEfjha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b8b330-fd00-4422-ed58-be88e5a5dcfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.526005>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.4863234>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.374054>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.97208>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.745561>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=8.73193>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.553021>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.269989>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.7417717>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.813118>}\n",
            "\n",
            "CPU times: user 5.15 s, sys: 151 ms, total: 5.3 s\n",
            "Wall time: 6.11 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-xqtsMbCUp2"
      },
      "source": [
        "While it's easier to debug without a `tf.function` it does give a performance boost. So now that the `_train_step` method is working, try the `tf.function`-wrapped `_tf_train_step`, to maximize performance while training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFUsTKQx0jaH"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-bgU59jrztQ"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC8bRv_Gr3H9"
      },
      "outputs": [],
      "source": [
        "translator.use_tf_function = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKMYNF_sIFb9"
      },
      "source": [
        "The first call will be slow, because it traces the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLQZsX2dp1QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34592df8-3096-4d4e-c021-ff1656031c84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.6645026>}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "translator.train_step([example_input_batch, example_target_batch])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3t2Hg7UISYi"
      },
      "source": [
        "But after that it's usually 2-3x faster than the eager `train_step` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzXXMwjXCqqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7aa07d-4550-4efa-81a6-223ed6a2cb10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.4523587>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.287389>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.1637926>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.041836>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.950547>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.950726>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.97709>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9448204>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8725815>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8098836>}\n",
            "\n",
            "CPU times: user 3.99 s, sys: 280 ms, total: 4.27 s\n",
            "Wall time: 3.62 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIvigTqaEcu1"
      },
      "source": [
        "A good test of a new model is to see that it can overfit a single batch of input. Try it, the loss should quickly go to zero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-dIWMIBqK7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "bae8ba3f-e0eb-460c-c4d3-9cdd8d2be8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd0a5809d10>]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI02XFjoEt1k"
      },
      "source": [
        "Now that you're confident that the training step is working, build a fresh copy of the model to train from scratch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emgfgh4tAmJt"
      },
      "outputs": [],
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpObfY22IddU"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "While there's nothing wrong with writing your own custom training loop, implementing the `Model.train_step` method, as in the previous section, allows you to run `Model.fit` and avoid rewriting all that boiler-plate code.\n",
        "\n",
        "This tutorial only trains for a couple of epochs, so use a `callbacks.Callback` to collect the history of batch losses, for plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7m4mtnj80sq"
      },
      "outputs": [],
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQd_esVVoSf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acba181c-95e2-4526-84a3-87e9df05d891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "30/30 [==============================] - 19s 431ms/step - batch_loss: 4.9594\n",
            "Epoch 2/200\n",
            "30/30 [==============================] - 13s 445ms/step - batch_loss: 3.9568\n",
            "Epoch 3/200\n",
            "30/30 [==============================] - 13s 450ms/step - batch_loss: 3.6906\n",
            "Epoch 4/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 3.3044\n",
            "Epoch 5/200\n",
            "30/30 [==============================] - 13s 423ms/step - batch_loss: 2.9405\n",
            "Epoch 6/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 2.5889\n",
            "Epoch 7/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 2.2127\n",
            "Epoch 8/200\n",
            "30/30 [==============================] - 13s 438ms/step - batch_loss: 1.8747\n",
            "Epoch 9/200\n",
            "30/30 [==============================] - 13s 449ms/step - batch_loss: 1.6074\n",
            "Epoch 10/200\n",
            "30/30 [==============================] - 13s 448ms/step - batch_loss: 1.3938\n",
            "Epoch 11/200\n",
            "30/30 [==============================] - 13s 415ms/step - batch_loss: 1.2131\n",
            "Epoch 12/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 1.0726\n",
            "Epoch 13/200\n",
            "30/30 [==============================] - 12s 416ms/step - batch_loss: 0.9521\n",
            "Epoch 14/200\n",
            "30/30 [==============================] - 14s 438ms/step - batch_loss: 0.8535\n",
            "Epoch 15/200\n",
            "30/30 [==============================] - 13s 421ms/step - batch_loss: 0.7701\n",
            "Epoch 16/200\n",
            "30/30 [==============================] - 13s 433ms/step - batch_loss: 0.6903\n",
            "Epoch 17/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.6306\n",
            "Epoch 18/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.5685\n",
            "Epoch 19/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.5151\n",
            "Epoch 20/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.4697\n",
            "Epoch 21/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.4266\n",
            "Epoch 22/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 0.3914\n",
            "Epoch 23/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.3611\n",
            "Epoch 24/200\n",
            "30/30 [==============================] - 13s 431ms/step - batch_loss: 0.3308\n",
            "Epoch 25/200\n",
            "30/30 [==============================] - 13s 432ms/step - batch_loss: 0.3101\n",
            "Epoch 26/200\n",
            "30/30 [==============================] - 13s 431ms/step - batch_loss: 0.2854\n",
            "Epoch 27/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.2638\n",
            "Epoch 28/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.2460\n",
            "Epoch 29/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.2361\n",
            "Epoch 30/200\n",
            "30/30 [==============================] - 14s 457ms/step - batch_loss: 0.2245\n",
            "Epoch 31/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.2109\n",
            "Epoch 32/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.2036\n",
            "Epoch 33/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1945\n",
            "Epoch 34/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 0.1885\n",
            "Epoch 35/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 0.1827\n",
            "Epoch 36/200\n",
            "30/30 [==============================] - 13s 438ms/step - batch_loss: 0.1770\n",
            "Epoch 37/200\n",
            "30/30 [==============================] - 13s 438ms/step - batch_loss: 0.1723\n",
            "Epoch 38/200\n",
            "30/30 [==============================] - 13s 419ms/step - batch_loss: 0.1687\n",
            "Epoch 39/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1664\n",
            "Epoch 40/200\n",
            "30/30 [==============================] - 13s 424ms/step - batch_loss: 0.1587\n",
            "Epoch 41/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1577\n",
            "Epoch 42/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1544\n",
            "Epoch 43/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1527\n",
            "Epoch 44/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1517\n",
            "Epoch 45/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1486\n",
            "Epoch 46/200\n",
            "30/30 [==============================] - 14s 448ms/step - batch_loss: 0.1480\n",
            "Epoch 47/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1470\n",
            "Epoch 48/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1481\n",
            "Epoch 49/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1461\n",
            "Epoch 50/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1447\n",
            "Epoch 51/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1467\n",
            "Epoch 52/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1504\n",
            "Epoch 53/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.1501\n",
            "Epoch 54/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1465\n",
            "Epoch 55/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 0.1462\n",
            "Epoch 56/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1450\n",
            "Epoch 57/200\n",
            "30/30 [==============================] - 13s 438ms/step - batch_loss: 0.1434\n",
            "Epoch 58/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1420\n",
            "Epoch 59/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1402\n",
            "Epoch 60/200\n",
            "30/30 [==============================] - 13s 447ms/step - batch_loss: 0.1386\n",
            "Epoch 61/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1375\n",
            "Epoch 62/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 0.1360\n",
            "Epoch 63/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1347\n",
            "Epoch 64/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.1355\n",
            "Epoch 65/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1303\n",
            "Epoch 66/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1334\n",
            "Epoch 67/200\n",
            "30/30 [==============================] - 13s 431ms/step - batch_loss: 0.1343\n",
            "Epoch 68/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1337\n",
            "Epoch 69/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 0.1329\n",
            "Epoch 70/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1325\n",
            "Epoch 71/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1337\n",
            "Epoch 72/200\n",
            "30/30 [==============================] - 13s 446ms/step - batch_loss: 0.1313\n",
            "Epoch 73/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1318\n",
            "Epoch 74/200\n",
            "30/30 [==============================] - 14s 452ms/step - batch_loss: 0.1306\n",
            "Epoch 75/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.1315\n",
            "Epoch 76/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.1314\n",
            "Epoch 77/200\n",
            "30/30 [==============================] - 13s 422ms/step - batch_loss: 0.1298\n",
            "Epoch 78/200\n",
            "30/30 [==============================] - 13s 447ms/step - batch_loss: 0.1318\n",
            "Epoch 79/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.1305\n",
            "Epoch 80/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1334\n",
            "Epoch 81/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1332\n",
            "Epoch 82/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 0.1380\n",
            "Epoch 83/200\n",
            "30/30 [==============================] - 13s 424ms/step - batch_loss: 0.1446\n",
            "Epoch 84/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.1542\n",
            "Epoch 85/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1540\n",
            "Epoch 86/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1498\n",
            "Epoch 87/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1444\n",
            "Epoch 88/200\n",
            "30/30 [==============================] - 13s 431ms/step - batch_loss: 0.1404\n",
            "Epoch 89/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1386\n",
            "Epoch 90/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1360\n",
            "Epoch 91/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1312\n",
            "Epoch 92/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1316\n",
            "Epoch 93/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 0.1291\n",
            "Epoch 94/200\n",
            "30/30 [==============================] - 13s 438ms/step - batch_loss: 0.1305\n",
            "Epoch 95/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1281\n",
            "Epoch 96/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1289\n",
            "Epoch 97/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1276\n",
            "Epoch 98/200\n",
            "30/30 [==============================] - 13s 433ms/step - batch_loss: 0.1276\n",
            "Epoch 99/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1279\n",
            "Epoch 100/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1258\n",
            "Epoch 101/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 0.1280\n",
            "Epoch 102/200\n",
            "30/30 [==============================] - 13s 432ms/step - batch_loss: 0.1294\n",
            "Epoch 103/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.1263\n",
            "Epoch 104/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1265\n",
            "Epoch 105/200\n",
            "30/30 [==============================] - 13s 420ms/step - batch_loss: 0.1267\n",
            "Epoch 106/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 0.1261\n",
            "Epoch 107/200\n",
            "30/30 [==============================] - 13s 451ms/step - batch_loss: 0.1244\n",
            "Epoch 108/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1272\n",
            "Epoch 109/200\n",
            "30/30 [==============================] - 13s 427ms/step - batch_loss: 0.1278\n",
            "Epoch 110/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.1257\n",
            "Epoch 111/200\n",
            "30/30 [==============================] - 13s 429ms/step - batch_loss: 0.1263\n",
            "Epoch 112/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1255\n",
            "Epoch 113/200\n",
            "30/30 [==============================] - 13s 438ms/step - batch_loss: 0.1246\n",
            "Epoch 114/200\n",
            "30/30 [==============================] - 13s 421ms/step - batch_loss: 0.1250\n",
            "Epoch 115/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 0.1274\n",
            "Epoch 116/200\n",
            "30/30 [==============================] - 13s 444ms/step - batch_loss: 0.1249\n",
            "Epoch 117/200\n",
            "30/30 [==============================] - 13s 447ms/step - batch_loss: 0.1287\n",
            "Epoch 118/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1266\n",
            "Epoch 119/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1272\n",
            "Epoch 120/200\n",
            "30/30 [==============================] - 13s 429ms/step - batch_loss: 0.1254\n",
            "Epoch 121/200\n",
            "30/30 [==============================] - 13s 448ms/step - batch_loss: 0.1272\n",
            "Epoch 122/200\n",
            "30/30 [==============================] - 13s 417ms/step - batch_loss: 0.1275\n",
            "Epoch 123/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1285\n",
            "Epoch 124/200\n",
            "30/30 [==============================] - 13s 431ms/step - batch_loss: 0.1282\n",
            "Epoch 125/200\n",
            "30/30 [==============================] - 13s 433ms/step - batch_loss: 0.1288\n",
            "Epoch 126/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1358\n",
            "Epoch 127/200\n",
            "30/30 [==============================] - 13s 449ms/step - batch_loss: 0.1401\n",
            "Epoch 128/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1430\n",
            "Epoch 129/200\n",
            "30/30 [==============================] - 13s 432ms/step - batch_loss: 0.1444\n",
            "Epoch 130/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1457\n",
            "Epoch 131/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1459\n",
            "Epoch 132/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1423\n",
            "Epoch 133/200\n",
            "30/30 [==============================] - 13s 432ms/step - batch_loss: 0.1369\n",
            "Epoch 134/200\n",
            "30/30 [==============================] - 13s 438ms/step - batch_loss: 0.1329\n",
            "Epoch 135/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1299\n",
            "Epoch 136/200\n",
            "30/30 [==============================] - 13s 417ms/step - batch_loss: 0.1274\n",
            "Epoch 137/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1275\n",
            "Epoch 138/200\n",
            "30/30 [==============================] - 13s 423ms/step - batch_loss: 0.1262\n",
            "Epoch 139/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1241\n",
            "Epoch 140/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1235\n",
            "Epoch 141/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1236\n",
            "Epoch 142/200\n",
            "30/30 [==============================] - 13s 424ms/step - batch_loss: 0.1243\n",
            "Epoch 143/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1226\n",
            "Epoch 144/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.1235\n",
            "Epoch 145/200\n",
            "30/30 [==============================] - 13s 452ms/step - batch_loss: 0.1245\n",
            "Epoch 146/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1229\n",
            "Epoch 147/200\n",
            "30/30 [==============================] - 13s 418ms/step - batch_loss: 0.1248\n",
            "Epoch 148/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.1262\n",
            "Epoch 149/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1243\n",
            "Epoch 150/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1275\n",
            "Epoch 151/200\n",
            "30/30 [==============================] - 13s 436ms/step - batch_loss: 0.1240\n",
            "Epoch 152/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 0.1248\n",
            "Epoch 153/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1239\n",
            "Epoch 154/200\n",
            "30/30 [==============================] - 13s 425ms/step - batch_loss: 0.1224\n",
            "Epoch 155/200\n",
            "30/30 [==============================] - 13s 439ms/step - batch_loss: 0.1239\n",
            "Epoch 156/200\n",
            "30/30 [==============================] - 13s 447ms/step - batch_loss: 0.1242\n",
            "Epoch 157/200\n",
            "30/30 [==============================] - 13s 440ms/step - batch_loss: 0.1235\n",
            "Epoch 158/200\n",
            "30/30 [==============================] - 13s 429ms/step - batch_loss: 0.1240\n",
            "Epoch 159/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.1246\n",
            "Epoch 160/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1246\n",
            "Epoch 161/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1244\n",
            "Epoch 162/200\n",
            "30/30 [==============================] - 13s 449ms/step - batch_loss: 0.1233\n",
            "Epoch 163/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1247\n",
            "Epoch 164/200\n",
            "30/30 [==============================] - 13s 420ms/step - batch_loss: 0.1250\n",
            "Epoch 165/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1253\n",
            "Epoch 166/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1228\n",
            "Epoch 167/200\n",
            "30/30 [==============================] - 13s 423ms/step - batch_loss: 0.1232\n",
            "Epoch 168/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1235\n",
            "Epoch 169/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1227\n",
            "Epoch 170/200\n",
            "30/30 [==============================] - 13s 425ms/step - batch_loss: 0.1228\n",
            "Epoch 171/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1265\n",
            "Epoch 172/200\n",
            "30/30 [==============================] - 13s 426ms/step - batch_loss: 0.1269\n",
            "Epoch 173/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1239\n",
            "Epoch 174/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1249\n",
            "Epoch 175/200\n",
            "30/30 [==============================] - 13s 429ms/step - batch_loss: 0.1240\n",
            "Epoch 176/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1229\n",
            "Epoch 177/200\n",
            "30/30 [==============================] - 13s 425ms/step - batch_loss: 0.1235\n",
            "Epoch 178/200\n",
            "30/30 [==============================] - 13s 445ms/step - batch_loss: 0.1258\n",
            "Epoch 179/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1250\n",
            "Epoch 180/200\n",
            "30/30 [==============================] - 13s 433ms/step - batch_loss: 0.1245\n",
            "Epoch 181/200\n",
            "30/30 [==============================] - 13s 437ms/step - batch_loss: 0.1235\n",
            "Epoch 182/200\n",
            "30/30 [==============================] - 13s 447ms/step - batch_loss: 0.1261\n",
            "Epoch 183/200\n",
            "30/30 [==============================] - 13s 432ms/step - batch_loss: 0.1284\n",
            "Epoch 184/200\n",
            "30/30 [==============================] - 13s 444ms/step - batch_loss: 0.1276\n",
            "Epoch 185/200\n",
            "30/30 [==============================] - 13s 431ms/step - batch_loss: 0.1270\n",
            "Epoch 186/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1278\n",
            "Epoch 187/200\n",
            "30/30 [==============================] - 13s 442ms/step - batch_loss: 0.1255\n",
            "Epoch 188/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1272\n",
            "Epoch 189/200\n",
            "30/30 [==============================] - 13s 424ms/step - batch_loss: 0.1257\n",
            "Epoch 190/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1271\n",
            "Epoch 191/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1279\n",
            "Epoch 192/200\n",
            "30/30 [==============================] - 13s 430ms/step - batch_loss: 0.1263\n",
            "Epoch 193/200\n",
            "30/30 [==============================] - 13s 447ms/step - batch_loss: 0.1281\n",
            "Epoch 194/200\n",
            "30/30 [==============================] - 13s 435ms/step - batch_loss: 0.1298\n",
            "Epoch 195/200\n",
            "30/30 [==============================] - 13s 428ms/step - batch_loss: 0.1282\n",
            "Epoch 196/200\n",
            "30/30 [==============================] - 13s 443ms/step - batch_loss: 0.1260\n",
            "Epoch 197/200\n",
            "30/30 [==============================] - 13s 441ms/step - batch_loss: 0.1265\n",
            "Epoch 198/200\n",
            "30/30 [==============================] - 13s 434ms/step - batch_loss: 0.1238\n",
            "Epoch 199/200\n",
            "30/30 [==============================] - 13s 433ms/step - batch_loss: 0.1234\n",
            "Epoch 200/200\n",
            "30/30 [==============================] - 13s 444ms/step - batch_loss: 0.1262\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd094296c90>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "train_translator.fit(dataset, epochs=200,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38rLdlmtQHCm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "6259d573-b17e-40f8-ca08-09171b1e8b8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0S_O_RzHmfe"
      },
      "source": [
        "The visible jumps in the plot are at the epoch boundaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Translate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO-CLL1LVBbM"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBQzFZ9uWU79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4ebb82-cd2c-4058-d272-bb5a2f524653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59PN-UxqYrU"
      },
      "source": [
        "### Convert token IDs to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IjwKTwtmdFf"
      },
      "outputs": [],
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "912aV0K7r90w"
      },
      "outputs": [],
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWCMHdoS32QN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5152f45f-7e5a-4c81-ff01-cf315f2ee7f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'land fingersnails', b'babylonia healing', b'ocean flavour',\n",
              "       b'ocean lai', b'vegetable mask'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC9De_kAqtaE"
      },
      "source": [
        "### Sample from the decoder's predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5tno-2ksJv6"
      },
      "source": [
        "This function takes the decoder's logit outputs and samples token IDs from that distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lfuj3GcdD6e"
      },
      "outputs": [],
      "source": [
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "  \n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DpDnBdBdL9_"
      },
      "outputs": [],
      "source": [
        "Translator.sample = sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwdHfGEfsmy5"
      },
      "source": [
        "Test run this function on some random inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwLT0nxXym80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4279e67-521f-44b6-b0af-a5a55bd711d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[ 771],\n",
              "       [2965],\n",
              "       [ 470],\n",
              "       [ 955],\n",
              "       [2422]])>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEWIKFIJ2HWM"
      },
      "source": [
        "### Implement the translation loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmOvVrZmwAxg"
      },
      "outputs": [],
      "source": [
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "    \n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOmd8Y269MG3"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_unrolled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxYXf3GNKKLS"
      },
      "source": [
        "Run it on a simple input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd2rgyHwVVrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e206fee9-d02d-4a00-ae31-529ec0ef9fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combo\n",
            "combo\n",
            "combo\n",
            "soju\n",
            "vodka\n",
            "tiger can\n",
            "tiger bottle\n",
            "crystal tiger can\n",
            "crystal tiger can\n",
            "coca\n",
            "sprite\n",
            "water\n",
            "red bull\n",
            "quy nhon beer\n",
            "bivina beer\n",
            "strong bow\n",
            "sauteed water spinach with garlic\n",
            "sauteed spinach with garlic\n",
            "sauteed borecole with garlic\n",
            "okra with garlic\n",
            "french fries\n",
            "fried frog skin with sauce\n",
            "crispy fried frog skin\n",
            "roasted frog skin with salt\n",
            "beans fried\n",
            "jellyfish with fine shrimp sauce\n",
            "stir fried baby corn with scallion\n",
            "stir fried corn with shrimp\n",
            "fried milk sentinel crab with fish sauce\n",
            "fried milk sentinel crab with salt\n",
            "vietnamese crispy spring shirmp roll\n",
            "pork ears salad\n",
            "jellyfish salad\n",
            "seafood salad\n",
            "chicken feet without bone\n",
            "beef salad\n",
            "rare beef with lemons\n",
            "octopus salad\n",
            "shrimp salad\n",
            "german sausage\n",
            "baked oysters\n",
            "grilled eggplant\n",
            "grilled fish ball beef ball shrimp ball\n",
            "grilled dumplings\n",
            "grilled pigs guts\n",
            "grilled chicken gizzard\n",
            "grilled squid\n",
            "grilled shrimp\n",
            "grilled octopus\n",
            "baked ribs bbq\n",
            "baked bacon\n",
            "grilled frog\n",
            "grilled american short plate\n",
            "short plate roll mushroom\n",
            "short plate roll cheese\n",
            "spicy grilled beef\n",
            "grilled beef piper lolot\n",
            "grilled belly\n",
            "oysters with cheese\n",
            "grilled oyster with scallion oil\n",
            "grilled clams\n",
            "grilled scallop\n",
            "grilled snails with green pepper\n",
            "grilled pork noodles hanoi\n",
            "grilled milk sentinel crabs\n",
            "grilled shrimp\n",
            "grilled octopus with salt and chilli\n",
            "spicy grilled beef\n",
            "grilled beef with piper lolot\n",
            "spicy mushroom beef roll\n",
            "fried license\n",
            "stir fried guts with turmeric\n",
            "clams steam with lemongrass\n",
            "clams with thailand flavours\n",
            "spicy stir fried fros\n",
            "fried frog with lime leaves\n",
            "roasted salted frog\n",
            "fried frog with fish sauce\n",
            "fried frog with butter\n",
            "meat bone fried with salt\n",
            "fried cartilage with fish sauce\n",
            "fried chicken wings with spicy shrimp salt\n",
            "fried chicken wings with fish sauce\n",
            "butterfried chicken wings\n",
            "steamed snail\n",
            "stir fried snail with citronella\n",
            "um buou snails\n",
            "stir fried razor clam with citronella\n",
            "stir fried razor clam with butter and garlic\n",
            "stirfried fingersnails with spinach\n",
            "roast duck tongue with salt\n",
            "roast duck tongue with sauce\n",
            "cana fried with salt\n",
            "cana steamed with citronella\n",
            "cana crab fried with salt\n",
            "cana crab fried with butter\n",
            "chicken legs with ms ba sauce\n",
            "roasted chicken feet with salt\n",
            "oolong milk tea special full topping m\n",
            "oolong milk tea special full topping l\n",
            "CPU times: user 335 ms, sys: 15.5 ms, total: 350 ms\n",
            "Wall time: 330 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "input_text = tf.constant(inp[:100])\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "for i in range(100):\n",
        "  print(result['text'][i].numpy().decode())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JhTZ5hOptO-"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkccvHDvXCa8"
      },
      "source": [
        "Run the `tf.function` once to compile it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NzrixLvVBjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de24d99-105b-4750-c6ae-8124fcbf5520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19.4 s, sys: 438 ms, total: 19.9 s\n",
            "Wall time: 19.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USJdu00tVFbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6515f48f-78d3-4e9c-c2bb-368295e953bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combo\n",
            "combo\n",
            "\n",
            "CPU times: user 167 ms, sys: 19.2 ms, total: 187 ms\n",
            "Wall time: 234 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngywxv1WYO_O"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_symbolic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B8W4_MZdX0"
      },
      "source": [
        "But when you wrap it in a `tf.function` you'll notice two differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX6EF8KtYh20"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S0kQ-bBZswZ"
      },
      "source": [
        "First: Graph creation is much faster (~10x), since it doesn't create `max_iterations` copies of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq8d40RKYoJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4a76a8-7d91-4853-98e7-8b7e1aae5c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.21 s, sys: 21.6 ms, total: 1.23 s\n",
            "Wall time: 1.22 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ABEwtKIZ6eE"
      },
      "source": [
        "Second: The compiled function is much faster on small inputs (5x on this example), because it can break out of the loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5VdCLxPYrpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a57b53-fe30-47d2-ee6c-7b477bc7e1bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combo\n",
            "combo\n",
            "\n",
            "CPU times: user 55.8 ms, sys: 2.45 ms, total: 58.3 ms\n",
            "Wall time: 58.2 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMA9Pp71nzH9"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyvxT5V0_X5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac34d85-fa81-44a2-e0db-83accb340c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_2_layer_call_fn, encoder_2_layer_call_and_return_conditional_losses, decoder_2_layer_call_fn, decoder_2_layer_call_and_return_conditional_losses, embedding_4_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(translator, '/content/drive/MyDrive/translator',\n",
        "                    signatures={'serving_default': translator.tf_translate})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZGTEjsSyBDJ",
        "outputId": "59c898e3-9555-4494-aafb-c5d6e5f937b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I0j3i3ekOba"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('translator')\n",
        "result = reloaded.tf_translate(three_input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXZF__FZXJCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ca202f-98d6-43ba-bb4a-5abea8b85f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maguro style\n",
            "black tiger shrimp with special sauce\n",
            "goat brain\n",
            "\n",
            "CPU times: user 40.1 ms, sys: 4.38 ms, total: 44.5 ms\n",
            "Wall time: 32.8 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = reloaded.tf_translate(three_input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NMT-ATTENTION.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}